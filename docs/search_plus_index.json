{"./":{"url":"./","title":"介绍","keywords":"","body":"差分隐私算法基础 The Algorithmic Foundations of Differential Pivacy by Cynthia Dwork Chinese Translation 关于本书 本书起始于2019年08月，记录了本人从零开始学习 The Algorithmic Foundations of Differential Pivacy 的过程。由于差分隐私目前主要研究领域着重于学术界，对于 Cynthia Dwork 女士的《差分隐私算法基础》目前没有一本完整的中文翻译书籍。通过在学习过程中翻译该书籍有助于本人理解差分隐私概念与算法基础。因此希望将该书翻译成中文，能够帮助大家理解差分隐私概念，少走弯路，并且在此过程中督促本人学习差分隐私。 由于本书英文较为晦涩难懂，翻译过程中难免会添加一些个人理解、语义修正和删减，其中不乏错误之处，欢迎指正讨论。 原书作者 感谢英文原著作者 @Cynthia Dwork 和 @Aaron Roth《The Algorithmic Foundations of Differential Pivacy》。有了 Cynthia Dwork 女士才有了差分隐私的一切。 译者 guoJohnny @guoJohnny 项目源码 项目源码存放于 Github 上，https://github.com/guoJohnny/algorithmic-foundation-of-dp-zh-cn。 欢迎建议指正或直接贡献翻译 https://github.com/guoJohnny/algorithmic-foundation-of-dp-zh-cn/issues LICENSE 署名-非商业性使用-相同方式共享 4.0 (CC BY-NC-SA 4.0)。 Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-19 21:48:45 "},"Preface.html":{"url":"Preface.html","title":"前言","keywords":"","body":"前言 隐私保护数据分析的问题由来已久，涉及多个学科。随着有关个人的电子数据变得越来越详细，并且随着技术能够更强大地收集和管理这些数据，对隐私的鲁棒性、隐私的意义和隐私在数学上严格的定义需求不断增长，对满足隐私定义的算法需求也在不断增长。差分隐私就是这样的定义。 在讨论了差分隐私的含义之后，本书主要介绍了实现差分隐私的基本技术，并将这些技术应用于创造性的结合中（第3-7节），其中使用了'查询发布问题'作为示例。其中最重要的是：对比单纯用差分隐私计算替换非隐私的每个计算步骤这种实现方法，通过重新思考计算目标能有更好的结果。 尽管有一些惊人的强大的计算结果，但仍然存在根本的局限性——不仅局限于使用差分隐私可以实现什么目标，而且还局限于什么方法可以防止隐私被完全破坏（泄露）（第8节）。 实际上，本书中讨论的所有算法都针对不同计算能力的对手保持着不同的隐私。某些算法是计算密集型的，其他算法则为高效率的。攻击者和算法的计算复杂度均在第9节中讨论。 在第10节和第11节中，我们从基础知识转向查询发布以外的应用程序，讨论了用于机制设计和机器学习的差分私有方法。关于差分私有算法的绝大多数文献都考虑了要进行大量分析的单个静态数据库。在第12节中讨论了其他模型中的差分隐私，包括分布式数据库和数据流计算。 最后，这本书是对差分隐私问题和技术的全面介绍，但并不是要进行详尽的调查，因为到目前为止，在差分隐私方面有大量研究，我们可以只覆盖一小部分。 Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-02 19:13:07 "},"1-The-Promise-of-Differential-Privacy/Overview.html":{"url":"1-The-Promise-of-Differential-Privacy/Overview.html","title":"一、差分隐私的承诺","keywords":"","body":"一、差分隐私的承诺 差分隐私 描述了数据持有者对数据主体的承诺：“无论您将数据用于任何研究或分析，都不会受到不利影响或其他影响。” 差分数据库机制可以使机密数据广泛用于准确的数据分析，而无需诉诸数据清洗，数据使用协议，数据保护计划，或其他受限方面。但是，保证隐私性的同时，将消耗数据实用性：《信息恢复基本法》指出，对太多问题的过于准确的回答将以一种惊人的方式破坏隐私。关于差分隐私的算法研究的目标是将这种不可避免性推迟尽可能长的时间。 差分隐私解决了一个问题，即在学习公众数据信息的同时，对个人一无所知。 医学数据库可能会告诉我们，吸烟会导致癌症，影响保险公司对吸烟者长期医疗费用的看法。吸烟者受到分析的伤害了吗？如果保险公司知道他吸烟，他的保险费可能会上涨。他可能也会得到帮助。但保险公司学习他的健康风险，使他进入戒烟计划。吸烟者的隐私被侵犯了吗？当然，研究结束后对他的了解比以前更多，但他的信息是不是“泄露”了？差分隐私将认为它不是，理由是对吸烟者的影响是相同的独立于他是否在研究中。是这项研究得出的结论影响了吸烟者，而不是他在数据集中的存在与否影响了实验得出的结论。 差分隐私保证了相同的结论，例如，吸烟会导致癌症，这与是否有人选择进入或退出数据集无关。具体地说，它确保任何输出序列（对查询的响应）在“本质上”发生的可能性相同，与任何个体的存在或不存在无关。这里，概率被隐私机制（由数据持有者控制）所做的随机选择所取代，术语“本质上”被抽象为参数 ε。较小的 ε 将产生更好的隐私（和更不准确的响应）。 差分隐私是一个定义，而不是一个算法。对于给定的计算任务 T 和给定的 ε 值，将有许多不同的私有算法以 ε-差分隐私 方式实现 T。有些算法会比其他算法更准确。当 ε 很小时，很难为任务 T 找到一个高精度的ε-差分隐私算法，就像为一个特定的计算任务找到一个数值稳定的算法一样。 Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-09 21:29:23 "},"1-The-Promise-of-Differential-Privacy/Privacy-preserving-data-analysis.html":{"url":"1-The-Promise-of-Differential-Privacy/Privacy-preserving-data-analysis.html","title":"隐私保护的数据分析","keywords":"","body":"1.1 隐私保护的数据分析 差分隐私是针对隐私保护数据分析问题而提出的一种隐私定义。我们简要地讨论了解决隐私保护的其他方式的一些问题（个人认为：此处的其他方式应该是：属性隐藏、匿名、少量数据等隐私保护方式）。 数据不能完全匿名并且仍然有用 一般来说，数据越丰富，就越有趣和有用。这就产生了“匿名化”和“删除可识别个人信息”的概念，这些概念希望部分数据记录可以被掩盖，其余部分可以发布并用于分析。 然而，由于数据的丰富性使得“个人”数据属性可能与其他领域的数据属性相重合，比如邮政编码、出生日期和性别的组合，甚至三个电影的名字和一个独立的人观看这些电影的大致日期。这种“命名”功能可用于联动攻击，以将不同数据集中的“匿名”记录与非匿名记录进行匹配。有如下两个事例： 1.通过将匿名医疗遭遇数据与（公开提供的）选民登记记录相匹配，确定了马萨丘塞特政府的医疗记录。 2.通过与互联网电影数据库（IMDB）的链接，确定了 Netflix 用户，其观看历史记录包含在 Netflix 发布的匿名电影记录集合中，作为推荐竞赛的训练数据。 差分隐私能中和联动攻击：因为差分隐私是数据访问机制的一个属性，并且与对手可用的辅助信息（背景知识）的存在或不存在无关，访问 IMDb 用户数据将不能对存在 Netflix 训练集中的用户数据进行联动攻击,换言之，攻击在数据集中的用户成功的可能性不会超过不在数据集中的用户。 重标识“匿名”记录并非唯一风险 “匿名”数据记录的重新标识显然是不可取的，这不仅是因为重新标识本身（这肯定揭示了数据集中的成员身份），而且还因为记录可能包含损害信息，如果它与个人相关联，则可能会造成损害。在给定日期从特定紧急护理中心收集的医疗遭遇记录可能只列出少量不同的投诉或诊断。邻居在相关日期访问设施的附加信息给出了邻居病情的一系列可能诊断结果。可能无法将特定记录与邻居匹配这一事实为邻居提供了最低限度的隐私保护。 个人理解：此处的重标识“匿名”记录应该指的是上一小节中通过其他数据集共有属性对匿名数据进行标识。个人认为此处的邻居诊断例子是指，通过关联特定信息，虽然无法确切知道这个人患了什么病，但却缩小了其患病的种类，排除了多余信息，这样是否是种变相的隐私泄露？因为这样只能提供很小的隐私保护。 不具有保护性的大数据集查询 对于特定个体的查询无法准确地得到安全的回答，事实上，人们可能希望直接拒绝他们（如果在计算上无法识别他们）。但如下面的差分攻击所示，强迫查询超过大型集并不是万能的。假设攻击者已知X先生在某个医学数据库中。综上所述，这两个大问题的答案是 ： 1.“数据库中有多少人具有镰状细胞特征？” 2.“数据库中除了X外，还有多少人有镰状细胞的特征？” 通过这两个数据查询得出数据，交出X先生是否有镰状细胞特征。 个人理解：如果某种查询是不允许针对特定个人（这里指的是X）进行查询，只能针对大规模数据统计类查询，这种数据发布的方式也是不具有保护性的，能通过差分攻击攻击得到隐私数据，如标题所示，对大数据集的查询不具有保护性。 查询审查存在的问题 查询审核有问题。如果根据历史记录，回答当前的查询会损害隐私，那么人们可能会倾向于审查查询和响应的序列，以阻止任何响应。例如，审核员可能在寻找可能构成差分攻击的成对查询。这种方法有两个困难。首先，拒绝回答一个问题本身就有可能被披露。第二，查询审计在计算上是不可行的；事实上，如果查询语言足够丰富，则甚至不存在算法过程来判断一对查询是否构成差分攻击。（审核、防止差分攻击语句是不现实的） “不安全”的摘要统计 在某种意义上，将摘要统计作为隐私解决方案是失败的，是直接来自上述差分攻击。摘要统计的其他问题包括针对数据库的各种重建攻击，数据库中每个人都有一个要保护的“秘密位”。有用性目标可以是允许，例如，形式的问题“满足属性 p 的多少人具有秘密比特值 1 ？”。另一方面，对手的目标是增加猜测个人秘密的机会。第 8.1 节中描述的重建攻击显示了即使是这种类型的线性查询数也难以保护：除非引入足够的不精确性，否则几乎所有的秘密比特都可以重建。 公布汇总统计数据的风险的一个显著例证是，应用统计技术，最初是为了确认或驳斥个人 DNA 在法医学混合物中的存在，以裁定个人是否参与全基因组关联研究。根据人类基因组计划的一个网站，“单核苷酸多态性”（SNPs，发音为“snips”）是当基因组序列中的单核苷酸（A、T、C或G）改变时发生的 DNA 序列变异。例如，一个 SNP 可能会改变 AAGGCTAA 到 ATGGCTAA 的 DNA 序列。“在这种情况下，我们说有两个等位基因：A 和 T。对于这样一个 SNP，我们可以问，给定一个特定的参考群体，这两个可能等位基因的频率是多少？考虑到参考群体中 SNP 的等位基因频率，我们可以研究这些频率对于有特定疾病的亚群（即“病例”组）可能有什么不同，寻找与疾病相关的等位基因。因此，全基因组关联研究可能包含大量snp病例组的等位基因频率。根据定义，这些等位基因频率只是聚合的统计数据，而（错误的）假设是，通过这种聚合，它们保留了隐私。然而，考虑到个体的基因组数据，理论上有可能确定个体是否属于病例组（并且，因此，有疾病）。作为回应，国家卫生研究院和 Wellcome信托基金终止了公众从他们资助的研究中获取总频率数据的途径。 （受制于相关知识缺失，未能理解此段重建攻击和 DNA 事例，需要对第 8.1 节进行了解） 这是一个具有挑战性的问题，即使是对于差分隐私，因为涉及到大量的——数十万甚至一百万——测量，这些测量包含和关联了大群体中的小数量的个体。 长期的事实并不“好” 如果一个数据主体随着时间的推移而被跟踪，那么揭露数据个体长期的行为（例如购买面包）可能会有问题。举个例子，假设某人，他年复一年地定期买面包，直到突然转向很少买面包。一位分析师可能会得出结论，某人很可能被诊断为2型糖尿病。分析员可能是正确的，也可能是不正确的；不管怎样，某人的隐私都会受到伤害。 （此处原文为Ordinary Fact，根据下文内容来看，更应该表示为一种长期的普遍性结果，故将其翻译为“长期”） “少数人”原则 在某些情况下，一种特定的技术实际上可以为数据集的“典型”成员提供隐私保护，或者更普遍地说，为“大多数”成员提供隐私保护。在这种情况下，人们经常听到这样的说法，即这种技术是足够的，因为它损害了“少数”参与者的隐私。撇开那些对隐私最重要的人来说可能是离群者这一担忧不谈，“少数人”原则在本质上并不是没有价值的：需要做出社会判断，权衡成本和收益。一个清晰的隐私定义与“少数人”的理念相一致，但还没有发展出来；但是，对于单个数据集，“只有少数”的隐私可以通过随机选择行的子集并将其全部释放来实现（引理4.3，第4节）。抽样界限描述了统计分析的质量，可以在随机子样本上执行，它控制要释放的行数。当“少数人”的原则被拒绝时，差分隐私提供了另一种选择。 （个人理解为离群点更容易遭受差分攻击，需要在之后深入理解） Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-10 07:55:04 "},"1-The-Promise-of-Differential-Privacy/Bibliographic-notes.html":{"url":"1-The-Promise-of-Differential-Privacy/Bibliographic-notes.html","title":"参考文献","keywords":"","body":"参考文献 Sweeney [81] linked voter registration records to “anonymized” medical encounter data; Narayanan and Shmatikov carried out a linkage attack against anonymized ranking data published by Netflix [65]. The work on presence in a forensic mix is due to Homer et al. [46]. The first reconstruction attacks were due to Dinur and Nissim [18]. Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-10-29 08:32:55 "},"2-Basic-Terms/Overview.html":{"url":"2-Basic-Terms/Overview.html","title":"二、基本术语","keywords":"","body":"二、基本术语 本节提出了差分隐私的形式化定义，并列举了它的一些关键特性。 Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-02 19:11:19 "},"2-Basic-Terms/The-model-of-computation.html":{"url":"2-Basic-Terms/The-model-of-computation.html","title":"计算模型","keywords":"","body":"2.1 计算模型 我们假设存在一个可信的和可信赖的数据提供者，他将个人的数据保存在数据库 DDD 中，通常由若干 N 行组成。数据库每一行包含单个个体的数据，而隐私目标是同时保护每个个体行，同时允许对整个数据库进行统计分析。 在非交互式或离线的模型中，数据提供者会一次性地生成某种对象，例如“合成数据库”、“摘要统计数据集合”或“净化数据库（经数据清洗的数据库）”。发布后，数据提供者不再扮演任何角色，原始数据可能会被销毁。 查询是应用于数据库的函数。交互式或在线模型允许数据分析员自适应地询问查询，根据观察到的对先前查询的响应来决定下一个查询的位置。 可信的管理员可以被一组个人运行的协议所代替，这些协议使用加密技术来实现安全多方协议。但在大多数情况下，我们对加密假设不感兴趣。第12节描述了这一模型和文献中研究的其他模型。 当所有的查询都提前知道时，非交互模型应该提供最佳的准确性，因为它能够在知道查询结构的情况下关联噪声。相反，当事先不知道有关查询的信息时，非交互式模型会带来严峻的挑战，因为它必须为所有可能的查询提供答案。正如我们将看到的，为了确保隐私，甚至是防止隐私灾难，准确度必然会随着问题的数量而下降，对所有可能的问题提供准确的答案将是不可行的。 差分隐私机制是一种算法，它将一个数据库或一组全体数据类型 χ\\chiχ （所有可能的数据库行）、随机位和一组查询（可选）作为输入，并生成一个输出字符串。希望可以对输出字符串进行解码，以便对查询产生相对准确的答案。如果没有出现任何查询，那么我们就处于非交互式的情况下，希望输出字符串可以被解释为将来的查询提供答案。 在某些情况下，我们可能要求输出字符串是合成数据库。这种合成数据库是由所有可能的数据库行（χ\\chiχ）中得到的多集合组成。这种情况下的解码方法是对合成数据库进行查询，然后应用一些简单的变换，如缩放因子的乘法，使其近似于查询的真实答案。 Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-10 07:59:58 "},"2-Basic-Terms/Towards-defining-private-data-analysis.html":{"url":"2-Basic-Terms/Towards-defining-private-data-analysis.html","title":"定义隐私数据分析","keywords":"","body":"2.2 定义隐私数据分析 在数据分析的背景下可以这样定义隐私，即：要求分析人员在分析完成后对数据集中的任何个人的了解不超过分析开始前的了解。这一目标的形式化也是很自然的，要求对手对个人的前后认知（即访问数据库之前和之后的认知）不应该“差别过多”，或者对数据库的访问不应该“过多”地改变对手对任何个人的认知。如果数据库能提供任何信息，那么这种隐私的概念是不可能实现的。例如，假设对手的先前的错误认知是每个人都有2个左脚。对统计数据库的访问告诉我们，几乎每个人都有一只左脚和一只右脚。攻击者现在每个人是否有两个左脚持完全不同的看法。 （上段中‘前后认知’原文为‘prior and posterior view’，此处我将其理解为攻击者对个人的描述与认识。故将其翻译为认知。） 第一段中对隐私的定义即“查询前后对任何个体的认知差别足够小（nothing is learned）”，这种定义方法具有一部分吸引力，是因为如果对个人什么都没学到，那么分析就不会伤害到个人隐私。然而，“吸烟导致癌症”的例子表明，这种定义是有缺陷的，罪魁祸首是辅助信息（X先生吸烟）。 这种用 “nothing is learned” 定义隐私的方法让人想起密码系统的语义安全性。粗略地说，语义安全性是指从密文中学不到任何关于明文的信息。也就是说，在看到密文之后，关于明文的任何已知信息在看到密文之前都是已知的。因此，如果有辅助信息说密文是“dog”或“cat”的加密，则密文不会泄漏有关“dog”或“cat”中的哪个已加密的更多信息。形式上，这是通过比较窃听者猜测“狗”和“猫”中哪个被加密的能力与攻击者模拟器（保护者对攻击者进行模拟）的猜测狗”和“猫”能力进行建模的，但这里攻击者模拟器只具有辅助信息，无法接触到密文。如果对于攻击者以及所有辅助信息（对手和模拟器都是私有的），对手模拟器与窃听者的猜测几率基本相同，则系统享有语义安全性。当然，为了使系统有用，合法的接收者必须能够正确地解密消息。否则，语义安全就可以轻松实现。 （个人理解：此处作者将 “nothing is learned” 这种隐私定义的方法与密码学“语义安全”做类比，密码系统中可暴露的密文与隐私保护发布的数据类似，对于窃听者（攻击者）相当于是完全可接触的。这就要求隐私系统与密码系统一样，拥有防范攻击者拥有辅助信息进行攻击的能力（背景知识攻击）。上文提到“窃听者和攻击者模拟器猜测几率是相同的”这一要求，表明了即使攻击者获取得到密文（发布的数据），并且攻击者有辅助信息的情况下，其猜测得到结果的概率与没有得到密文（发布的数据）猜测的结果一样。简单来说，攻击者只能用先验知识瞎猜，无法通过查询的信息得到后验知识。这样保证了攻击者想通过发布的数据得到个体的隐私数据是无用的。） 我们知道，在标准的计算假设下，语义安全的密码系统是存在，那么为什么我们不能构建语义安全的私有数据库机制，这种机制能保持单行秘密的同时得到查询的答案？ 首先，这个类比并不完美：在一个语义安全的密码系统中，有三个方面：消息发送者（加密明文消息的人）、消息接收者（解密密文的人）和窃听者。相比之下，在隐私数据分析的设置中，只有两个方面：管理者（类似于发送者）和数据分析者，这种数据分析者包括两种：1）接收对查询的信息响应（如合法接收者）2）试图从数据中获取对个人隐私有危害的信息（如窃听者）。由于合法接收者与窥探对手是同一方，因此与加密的类比存在缺陷：拒绝向对手提供所有信息意味着拒绝向数据分析者提供所有信息。 第二，和加密方案一样，我们要求隐私机制是有用的，这意味着它教给分析师一些她以前不知道的东西。这种教学对攻击者模拟器是不可用的；也就是说，攻击者模拟器不能“预测”分析员所学的知识。因此，我们可以将数据库视为随机（不可预测）的弱数据源，从中我们可以提取一些非常高质量的随机性，用作随机密码本（random pad）。这可以用于一种加密技术，在这种技术中，将秘密消息添加到一个随机值（“random pad”）中，以便生成一个字符串，该字符串的信息理论上隐藏了秘密。只有知道随机密码本的人才能知道这个秘密；对密码本一无所知的任何一方对这个秘密都一无所知，不管他或她的计算能力如何。给定对数据库的访问权限，分析员可以学习随机密码本，但是攻击者模拟器，没有给定对数据库的访问权限，对密码本一无所知。因此，将随机密码本加密秘密作为辅助信息，分析者可以解密秘密，但是攻击者模拟器对秘密一无所知。这导致攻击者/分析师学习秘密的能力和对手模拟器做同样事情的能力之间存在巨大差异，消除了任何远程类似语义安全的希望。 （个人理解：语义安全与隐私保护存在差异，无法完全类比，其一是因为密码系统是存在三方角色，而在隐私保护系统中，攻击者与分析者的角色对数据发布方来说是等同得到，这就造成了类比差异。其二，原因有待进一步理解。） 对于上述吸烟的导致癌症和隐私保护的类语义安全性两个例子来说，最大的障碍是攻击者拥有辅助信息。显然，即使在“合理”的辅助知识的背景下，隐私保障也必须保持，但把合理的辅助知识从实际的辅助知识中分离是有问题的。例如，使用政府数据库的分析师可能是一家大型搜索引擎公司的员工。什么“合理”假设的辅助知识信息能提供给这样的人？ （个人理解：允许额外的辅助信息的存在，但如何区别和量化这一合理性是个问题。对于本节，理解上仍然存在很多问题需要不断理解和修改。） Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-21 19:28:34 "},"2-Basic-Terms/Formalizing-differential-privacy_1.html":{"url":"2-Basic-Terms/Formalizing-differential-privacy_1.html","title":"形式化差分隐私（1）","keywords":"","body":"2.3 形式化差分隐私（1） 我们将从差分隐私的技术定义开始，然后继续解释它。差分隐私将通过过程提供隐私；特别是它将引入随机性。最早的隐私保护做法是使用随机响应技术，这是一种在社会科学中发展起来的技术，用于收集有关禁运或非法行为的统计信息（通过是否拥有财产 PPP 判断）。研究参与者通过下列做法报告他们是否有财产 PPP： 1.掷硬币。 2.如果是反面，那就如实回答。 3.如果是正面，则掷第二枚硬币，正面回答“是”，反面回答“否”。 “隐私”来源于对任何输出的合理否认；特别是，如果拥有财产 PPP 相当于从事非法行为，即使是“是”答案也不构成犯罪，因为无论被告是否实际拥有财产 PPP ，这个答案出现的概率至少为 1/41/41/4。准确度来自于对噪声产生过程的理解（随机分组中引入虚假的“是”和“否”答案）：预期的“是”答案的概率是：没有属性 PPP 的参与者概率的 1/41/41/4 加上有属性 PPP 的概率的 3/43/43/4 。因此，如果 ppp 是具有 ppp 属性的参与者的真实概率，则“是”答案的预期概率为 (1/4)(1−p)+(3/4)p=(1/4)+p/2(1/4)(1-p)+(3/4)p=(1/4)+p/2(1/4)(1−p)+(3/4)p=(1/4)+p/2。因此，我们可以将 ppp 估计为回答“是”的概率的两倍减去 1/21/21/2 ，即 2((1/4)+p/2)−1/22((1/4)+p/2)-1/22((1/4)+p/2)−1/2 (此处个人感觉有误) 。 注：此处令 PAP_APA​ 为真实的概率，PBP_BPB​ 为经过机制变换后得到的概率， 这样，可以由变换之后的概率PBP_BPB​得到真实概率PAP_APA​: PB=1/4(1−PA)+3/4PA=1/4+1/2PAPA=2∗PB−1/2 \\begin{aligned} P_B &= 1/4 (1 - P_A) + 3/4 P_A \\\\ &= 1/4 + 1/2 P_A \\\\ P_A &= 2 * P_B - 1/2 \\end{aligned} PB​PA​​=1/4(1−PA​)+3/4PA​=1/4+1/2PA​=2∗PB​−1/2​ （上述的例子可以得出，经过随机化之后，对个人数据是会有不确定性，无法得知个人是什么样的属性，但最后经过“抛硬币机制”处理后得到的总体概率却能还原出数据集原有总体概率。可以尝试，将原有的 PAP_APA​ 取任何值，都能从最后的 PBP_BPB​ 还原出来，但此时单个个体的属性是随机化的。） 随机化是必不可少的；更确切地说，任何非平凡的隐私都要对所有现有的或未来的辅助信息来源随机化处理（包括其他数据库、研究、网站、在线社区、闲话、报纸、政府统计等等）。下面我们来说明一个简单的混合参数。出于矛盾的原因，我们假设有一个非平凡的确定性算法。存在一个查询，并且有两个数据库在此查询下产生不同的输出。一次更改一行，我们看到存在一对仅在单行值上有所不同的数据库，在同一数据库上同一查询产生不同的输出。 知道该数据库是这两个几乎完全相同的数据库之一的对手将了解未知行中数据的值。 （注1：“非平凡的” 具有一定复杂度，需要一定脑力活动、加工过程才能得到的结果或结论。The antonym nontrivial is commonly used by engineers and mathematicians to indicate a statement or theorem that is not obvious or easy to prove. 摘自wikipedia） （注2:为引入随机化和相邻数据集做铺垫。） 因此，我们将需要讨论随机算法的输入和输出空间。 在本专论中，我们使用离散的概率空间。 有时我们会将算法描述为从连续分布中采样，但是应始终以适当的方式将其离散化为有限精度（请参见后文的备注2.1）。 通常，具有域 AAA 和（离散）范围 BBB 的随机算法将与从AAA到BBB上的概率单纯形的映射相关联，表示为Δ(B)\\Delta(B)Δ(B)： 定义2.1（概率单纯形） 给定一个离散集 BBB，将 BBB 上的概率单纯形，表示为 Δ(B)\\Delta(B)Δ(B) ，其定义为： Δ(B)={x∈R∣B∣:xi⩾0 for all i and ∑i=1∣B∣xi=1} \\Delta(B) = \\{ x \\in \\mathbb{R}^{|B|} : x_i \\geqslant 0\\ for\\ all\\ i\\ and\\ \\sum_{i=1}^{|B|}x_i = 1 \\} Δ(B)={x∈R∣B∣:xi​⩾0 for all i and i=1∑∣B∣​xi​=1} （个人理解：此处的 R\\mathbb{R}R 可以与数据库中的数据集合类比，xix_ixi​ 即映射后得到数据的类概率，将数据集映射到各个离散状态集合 BBB 的元素中，且这些映射产生离散点 xix_ixi​ 的概率之和为 111） （个人理解2:对概率单纯形定义进行拓展，即有一个包含R∣B∣\\mathbb{R}^{|B|}R∣B∣个分量的向量x→\\overrightarrow{x}x,其分量之和为111,如下： x→∈R∣B∣,x→=(x1,x2...x∣B∣)xi∈x→,∑i=1∣B∣xi=1,and xi⩾0 \\begin{aligned} \\overrightarrow{x} \\in \\mathbb{R}^{|B|},\\overrightarrow{x} = (x_1,x_2...x_{|B|}) \\\\ x_i \\in \\overrightarrow{x},\\sum_{i=1}^{|B|}x_i = 1,and \\ x_i \\geqslant 0 \\\\ \\end{aligned} x∈R∣B∣,x=(x1​,x2​...x∣B∣​)xi​∈x,i=1∑∣B∣​xi​=1,and xi​⩾0​       e.g. as the coin flip:\\ \\ \\ \\ \\ \\ e.g. \\ as \\ the \\ coin \\ flip:      e.g. as the coin flip: if B→={0,1},then R∣B∣=R×Rx→∈R×R (i.e:(x1,x2)∈x→)∑i=1∣B∣xi=∑i=12xi=x1+x2=1 \\begin{aligned} if \\ \\overrightarrow{B} = \\{ 0,1 \\},then \\ \\mathbb{R}^{|B|} = R \\times R \\\\ \\overrightarrow{x} \\in R \\times R \\ (i.e:(x_1,x_2) \\in \\overrightarrow{x}) \\\\ \\sum_{i=1}^{|B|}x_i = \\sum_{i=1}^{2}x_i = x_1 + x_2 = 1 \\end{aligned} if B={0,1},then R∣B∣=R×Rx∈R×R (i.e:(x1​,x2​)∈x)i=1∑∣B∣​xi​=i=1∑2​xi​=x1​+x2​=1​ ） 定义2.2（随机化算法） 具有域AAA和离散范围BBB的随机算法M\\mathcal{M}M 与 映射 M:A→Δ(B)M:A \\to \\Delta(B)M:A→Δ(B)相关联。 在输入a∈Aa∈Aa∈A时，算法M\\mathcal{M}M以概率M(a)bM(a)_bM(a)b​输出M(a)=b\\mathcal{M}(a)=bM(a)=b（b∈Bb∈Bb∈B）。概率空间包括了硬币翻转算法M\\mathcal{M}M的概率空间。 （个人理解：M\\mathcal{M}M 是种映射算法（机制），将原始域数据成为其他离散形式（比如直方图）。上文的翻转硬币机制就是该定义中的 M\\mathcal{M}M 。此处的M\\mathcal{M}M与映射 M:A→Δ(B)M:A \\to \\Delta(B)M:A→Δ(B)有联系但不相同，M\\mathcal{M}M指将原始数据变成其他数据的方法，M:A→Δ(B)M:A \\to \\Delta(B)M:A→Δ(B)是指从A→BA \\to BA→B的各个映射的概率。）） 我们将数据库 xxx 视为来自全集 χ\\chiχ 的记录的集合。用它们的直方图表示数据库通常会很方便：x∈N∣χ∣x \\in \\mathbb{N}^{|\\chi|}x∈N∣χ∣ ，其中每个项 xix_ixi​ 表示数据库 xxx 中元素的数量。 类型 i∈χi\\in\\chii∈χ（我们略微滥用了符号，让符号 N\\mathbb{N}N 表示所有非负整数的集合，包括零）。 在这个表示中，两个数据库 xxx 和 yyy 之间距离的自然度量将是它们的 ℓ1\\ell_1ℓ1​ 距离： 定义 2.3 (数据库之间距离) 将数据库的ℓ1\\ell_1ℓ1​ 范数距离表示为 ∣∣x∣∣1||x||_1∣∣x∣∣1​ 其定义为: ∣∣x∣∣1=∑i=1∣χ∣∣xi∣ ||x||_1 = \\sum_{i=1}^{|\\chi|}|x_i| ∣∣x∣∣1​=i=1∑∣χ∣​∣xi​∣ 数据库 xxx 和 yyy 之间的 ℓ1\\ell_1ℓ1​ 距离为 ∣∣x−y∣∣1||x-y||_1∣∣x−y∣∣1​ 注意到 ∣∣x∣∣1||x||_1∣∣x∣∣1​ 是衡量数据库 xxx 的大小（也就是说，数据库 xxx 包含的记录数），而 ∣∣x−y∣∣1||x-y||_1∣∣x−y∣∣1​ 表示数据库 xxx 和 yyy 之间相差多少条记录。我们称这种记录相差为1的数据库为相邻数据集。 数据库也可以由行的多集（ χ\\chiχ 的元素）甚至行的有序列表来表示(这是一组的特例,其中行号成为元素名称的一部分)。 在这种情况下，数据库之间的距离通常由汉明距离（即汉明距离不同）来衡量。 但是，除非另有说明，否则我们将使用上述直方图表示形式。 （但是请注意，即使直方图表示法在数学上更方便，在实际的实现中，多集表示通常也会更加简洁）。 现在，我们可以正式定义差分隐私了，这将直观地保证随机算法在相似输入数据库上的行为类似。 定义2.4 （差分隐私） 对于所有的S⊆Range(M)\\mathcal{S} \\subseteq Range(\\mathcal{M})S⊆Range(M) 且所有的 x,y∈N∣χ∣x,y\\in \\mathbb{N}^{|\\chi|}x,y∈N∣χ∣ 有 ∣∣x−y∣∣1≤1||x-y||_1 \\leq 1∣∣x−y∣∣1​≤1，如果满足下列关系： Pr[M(x)∈S]≤exp(ε)Pr[M(y)∈S]+δ Pr[\\mathcal{M}(x) \\in \\mathcal{S}] \\leq exp(\\varepsilon)Pr[\\mathcal{M}(y) \\in \\mathcal{S}] + \\delta Pr[M(x)∈S]≤exp(ε)Pr[M(y)∈S]+δ 则将这个域在 N∣χ∣\\mathbb{N}^{|\\chi|}N∣χ∣ 的随机算法 M\\mathcal{M}M 称为 (ε,δ)(\\varepsilon,\\delta)(ε,δ) 差分隐私(即 (ε,δ)–Differentially private(\\varepsilon,\\delta) \\text{--} Differentially \\ private(ε,δ)–Differentially private)。 特别的，如果 δ=0\\delta=0δ=0 ，则将 M\\mathcal{M}M 称为 ε\\varepsilonε 差分隐私(即 ε–Differentially private\\varepsilon \\text{--} Differentially \\ privateε–Differentially private)。 通常，我们对 δ\\deltaδ 的值感兴趣，该值小于多项式数据库大小的倒数。 特别是，δ\\deltaδ 值接近 1/∣∣x∣∣11/||x||_11/∣∣x∣∣1​ 是非常危险（因为在第1节中讨论“少数人”原则）：这种做法通过发布少量数据库参与者的完整记录来“保护隐私”（以获得可用性）。 但是，即使 δ\\deltaδ 可以忽略不计，ε\\varepsilonε 和 (ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私之间也存在理论上的区别。 其中最主要的是量化顺序的转换。 ε\\varepsilonε- 差分隐私可确保对于机制 M(x)\\mathcal{M}(x)M(x) 的每次运行，在每个相邻数据库上同时观察到的输出的可能性几乎相同。相反，从事后观察值得出结论， (ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私对于每对相邻数据库x, yx, \\ yx, y，当数据库是xxx，而不是yyy时，机制 M\\mathcal{M}M 或更大概率生成或小概率生成值 M(x)\\mathcal{M}(x)M(x) 。 但是，给定输出ξ∽M(x)\\xi \\backsim \\mathcal{M}(x)ξ∽M(x)，可能会找到一个数据库yyy，使得 ξ\\xiξ 在 yyy 上产生的可能性比数据库为 xxx 时的可能性大得多。 即，分布 M(y)\\mathcal{M}(y)M(y) 中的 ξ\\xiξ 的质量可以实质上大于分布 M(x)\\mathcal{M}(x)M(x) 中的 ξ\\xiξ 的质量。 所以，机制质量： LM(x)∣∣M(y)(ξ)=ln⁡(Pr[M(x)=ξ]Pr[M(y)=ξ]) \\mathcal{L}_{\\mathcal{M}(x)||\\mathcal{M}(y)}^{(\\xi)} = \\ln(\\frac{Pr\\lbrack \\mathcal{M}(x) = \\xi \\rbrack}{Pr\\lbrack \\mathcal{M}(y) = \\xi \\rbrack}) LM(x)∣∣M(y)(ξ)​=ln(Pr[M(y)=ξ]Pr[M(x)=ξ]​) 对我们至关重要。我们将其称为观察 ξ\\xiξ 导致的隐私损失。 这种损失可能是正的（当事件在xxx之下比在yyy之下更有可能发生），也可能是负的（当事件在yyy之下比xxx之下更有可能）。正如我们将在引理3.17看到，(ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私确保对于所有相邻的xxx、yyy，隐私损失的绝对值被ε\\varepsilonε界定的概率至少为1−δ1-\\delta1−δ。 与往常一样，概率空间位于机制M\\mathcal{M}M的硬币上。（over the coins of machanism M\\mathcal{M}M?这句话原文无法理解。） 差分隐私不受后处理的影响：在没有其他有关私有数据库的知识的情况下，数据分析人员无法计算私有算法M\\mathcal{M}M的输出函数，也无法使其差分隐私程度降低。 就是说，如果算法保护了个人的隐私，那么无论是在正式定义下，还是在任何直观的意义上，数据分析师都无法仅仅通过坐在角落里思考算法的输出来增加隐私损失。 形式上，具有（(ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私算法M\\mathcal{M}M的数据独立映射 fff 的组成也具有（(ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私： 命题2.1（后处理） 令 M:N∣χ∣→R\\mathcal{M}: \\mathbb{N}^{|\\chi|} \\to RM:N∣χ∣→R 是 (ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私随机算法。 令 f:R→R′f:R \\to R'f:R→R′为任意随机映射。 则 f∘M:N∣χ∣→R′f \\circ \\mathcal{M}: \\mathbb{N}^{|\\chi|} \\to R'f∘M:N∣χ∣→R′ 是 (ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私。 【证明】我们证明了一个确定性函数f:R→R′f:R \\to R'f:R→R′的命题。结果如下，因为任何随机映射都可以分解为确定性函数的凸组合，而差分隐私机制的凸组合是差分隐私的。 设任意一对相邻数据库 x,yx,yx,y 的 ∣∣x−y∣∣1≤1||x-y||_1 \\leq 1∣∣x−y∣∣1​≤1，且任意事件 S⊆R′S\\subseteq R'S⊆R′，设 T={r∈R:f(r)∈S}T = \\{ r \\in R: f(r) \\in S \\}T={r∈R:f(r)∈S} ，则： Pr[f(M(x)∈S)]=Pr[M(x)∈T]≤exp(ε)Pr[M(y)∈T]+δ=exp(ε)Pr[f(M(y))∈S]+δ \\begin{aligned} Pr\\lbrack f(\\mathcal{M}(x) \\in S) \\rbrack &= Pr[\\mathcal{M}(x) \\in T]\\\\ & \\leq exp(\\varepsilon)Pr[\\mathcal{M}(y) \\in T] + \\delta\\\\ &= exp(\\varepsilon)Pr[f(\\mathcal{M}(y)) \\in S] + \\delta \\end{aligned} Pr[f(M(x)∈S)]​=Pr[M(x)∈T]≤exp(ε)Pr[M(y)∈T]+δ=exp(ε)Pr[f(M(y))∈S]+δ​ 即证。 Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-10 11:59:30 "},"2-Basic-Terms/Formalizing-differential-privacy_2.html":{"url":"2-Basic-Terms/Formalizing-differential-privacy_2.html","title":"形式化差分隐私（2）","keywords":"","body":"2.3 形式化差分隐私（2） 从定义2.4可以立即得出 (ε,0)(\\varepsilon,0)(ε,0)- 差分隐私的合成很简单：两个(ε,0)(\\varepsilon,0)(ε,0)- 差分隐私机制的合成是 (2ε,0)(2\\varepsilon,0)(2ε,0)- 差分隐私。 这个定理再进一步拓展（即定理3.16:“ ε\\varepsilonε 和 δ\\deltaδ 相加定理”)： 设有 kkk 个差分隐私机制的合成，其中第 iii 个机制为 (εi,δi)(\\varepsilon_i,\\delta_i)(εi​,δi​)- 差分隐私。易知，当 1≤i≤k1 \\leq i \\leq k1≤i≤k时，kkk 个差分隐私机制合成的结果是 (∑i=1kεi,∑i=1kδi)(\\sum_{i=1}^{k}\\varepsilon_i,\\sum_{i=1}^{k}\\delta_i)(∑i=1k​εi​,∑i=1k​δi​)- 差分隐私。 群隐私：(ε,0)(\\varepsilon,0)(ε,0)- 差分隐私机制的群隐私也遵循从定义2.4，隐私保证的强度随群的大小线性下降。 （个人理解：由定义可知，机制的叠加不能增加差分隐私的隐私保护程度，相反会以线性方式增加 ε\\varepsilonε，进而增大隐私泄露的可能。下面试推导差分隐私合成增加: 定义 zzz 是 xxx 的相邻数据库，定义 yyy 是 zzz 的相邻数据库，且有两个差分隐私机制 M1,M2\\mathcal{M}_1,\\mathcal{M}_2M1​,M2​，将这两个满足(ε,0)(\\varepsilon,0)(ε,0)- 差分隐私机制合成： 根据定义2.4可得： Pr[M2(M1(x))∈S]≤exp(ε)Pr[M2(M1(z))∈S]≤[exp(ε)]2Pr[M2(M1(y))∈S] \\begin{aligned} Pr[\\mathcal{M}_2(\\mathcal{M}_1(x)) \\in \\mathcal{S}] &\\leq exp(\\varepsilon)Pr[\\mathcal{M}_2(\\mathcal{M}_1(z)) \\in \\mathcal{S}] \\\\ &\\leq \\lbrack exp(\\varepsilon) \\rbrack^2 Pr[\\mathcal{M}_2(\\mathcal{M}_1(y)) \\in \\mathcal{S}] \\end{aligned} Pr[M2​(M1​(x))∈S]​≤exp(ε)Pr[M2​(M1​(z))∈S]≤[exp(ε)]2Pr[M2​(M1​(y))∈S]​ 由上可得两者合成得 (2ε,0)(2\\varepsilon,0)(2ε,0)- 差分隐私） 定理2.2 对于大小为 kkk 的群，任何 (ε,0)(\\varepsilon,0)(ε,0)- 差分隐私机制M\\mathcal{M}M 是 (kε,0)(k\\varepsilon,0)(kε,0)- 差分隐私。也就是说，对于所有 ∣∣x−y∣∣1≤1||x-y||_1 \\leq 1∣∣x−y∣∣1​≤1 和所有 S⊆Range(M)\\mathcal{S} \\subseteq Range(\\mathcal{M})S⊆Range(M) : Pr[M(x)∈S]≤exp(kε)Pr[M(y)∈S] Pr[\\mathcal{M}(x) \\in \\mathcal{S}] \\leq exp(k\\varepsilon)Pr[\\mathcal{M}(y) \\in \\mathcal{S}] Pr[M(x)∈S]≤exp(kε)Pr[M(y)∈S] 概率空间在机M\\mathcal{M}M的硬币翻转上。 例如，这解决了包括多个家庭成员的调查中的隐私问题 [1]\\ ^{[1]} [1]。 更普遍的说，差分隐私的组成和群体隐私不是同一回事，第3.5.2节（定理3.20）中改善的组成范围（实质上改善了kkk因子）不会（也不能）为群体带来相同的收益隐私，即使 δ=0\\delta=0δ=0。 （原文注[1]：然而，随着群体的扩大，隐私保障也随之恶化，这正是我们想要的：很明显，如果我们用一个完全不同的群体，比如健康的青少年，来代替整个被调查的癌症患者群体，对于那些经常每天跑三英里的受访者，我们应该得到不同的答案。虽然(ε,δ)(\\varepsilon,\\delta)(ε,δ) 差分隐私保密性类似，但近似项 δ\\deltaδ 受到了很大的冲击，我们只得到 kkk 个群的(kε,ke(k−1)ε)(k\\varepsilon,ke^{(k-1)\\varepsilon})(kε,ke(k−1)ε)-差分隐私。） （个人理解不了，有待后期学习) 2.3.1 差分隐私的承诺 经济观点 ：差分隐私承诺保护个人信息免受任何额外的损害，这种伤害的出现是因为他们的数据在私有数据库 xxx 中。如果他们的数据不是 xxx 的一部分，他们就不会遭到这些损害。尽管一旦差分隐私机制 M\\mathcal{M}M 的结果 M(x)\\mathcal{M}(x)M(x) 发布，个人信息确实可能会面临伤害。差分隐私承诺，他们选择参与数据发布并不会显著增加伤害的可能性。这是一个非常功利的隐私定义，因为当一个人决定是否将她的数据包含在差分隐私数据库中时，她会考虑这种差异：与没参与数据发布相比，她的个人信息在参与后遭到损害的概率。因为她无法控制数据库的其余内容，所以考虑到了差别隐私的承诺，她能确信从未来的损害来看，参与与不参与数据发布造成的影响几乎没什么差别。如果给予任何激励———从利他主义到金钱回报——差分隐私可能会说服她允许使用她的数据。这种直觉可以在效用理论的意义上被形式化，我们在这里简单地描述一下。 考虑一个对所有可能的未来事件集合有任意偏好的个体 iii ，我们用 A\\mathcal{A}A 来表示。这些偏好由一个效用函数 uiu_iui​ 来表示 ui:A→R⩾0u_i:\\mathcal{A} \\to \\mathbb{R}_{\\geqslant0}ui​:A→R⩾0​ ，我们说个体iii在 a∈Aa \\in \\mathcal{A}a∈A 的情况下,其效用为 ui(a)u_i(a)ui​(a)。假设 x∈N∣χ∣x \\in \\mathbb{N}^{|\\chi|}x∈N∣χ∣ 是一个包含个体 iii 的私有数据的数据集，M\\mathcal{M}M 是一个 ε\\varepsilonε- 差分隐私算法。设yyy为与xxx 相邻的数据集，它不包括个体 iii 的数据（∣∣x−y∣∣1≤1||x-y||_1 \\leq 1∣∣x−y∣∣1​≤1）。并设 f:Range(M)→Δ(A)f:Range(\\mathcal{M} ) \\to \\Delta(\\mathcal{A})f:Range(M)→Δ(A) 为（任意）函数，该函数决定未来事件 A\\mathcal{A}A 的分布，以机制M的输出为条件（注：此处Δ(A)\\Delta(\\mathcal{A})Δ(A)函数为定义2.1（概率单纯形）函数）。通过差分隐私的保证以及命题2.1保证的任意后处理的弹性，我们可以有： Ea∽f(M(x))[ui(a)]=∑a∈Aui(a)⋅Prf(M(x))[a]≤∑a∈Aui(a)⋅exp(ε)Prf(M(y))[a]=exp(ε)Ea∽f(M(y))[ui(a)] \\begin{aligned} \\mathbb{E}_{a \\backsim f(\\mathcal{M}(x))}[u_i(a)] &= \\sum_{a \\in \\mathcal{A}}u_i(a) \\cdotp \\underset{f(\\mathcal{M}(x))}{Pr}[a] \\\\ &\\leq \\sum_{a \\in \\mathcal{A}} u_i(a) \\cdotp exp(\\varepsilon) \\underset{f(\\mathcal{M}(y))}{Pr}[a] \\\\ &= exp(\\varepsilon)\\mathbb{E}_{a \\backsim f(\\mathcal{M}(y))}[u_i(a)] \\end{aligned} Ea∽f(M(x))​[ui​(a)]​=a∈A∑​ui​(a)⋅f(M(x))Pr​[a]≤a∈A∑​ui​(a)⋅exp(ε)f(M(y))Pr​[a]=exp(ε)Ea∽f(M(y))​[ui​(a)]​ 同理， Ea∽f(M(x))[ui(a)]⩾exp(−ε)Ea∽f(M(y))[ui(a)] \\mathbb{E}_{a \\backsim f(\\mathcal{M}(x))}[u_i(a)] \\geqslant exp(-\\varepsilon)\\mathbb{E}_{a \\backsim f(\\mathcal{M}(y))}[u_i(a)] Ea∽f(M(x))​[ui​(a)]⩾exp(−ε)Ea∽f(M(y))​[ui​(a)] 因此，通过保证 ε\\varepsilonε- 差分隐私，数据分析师可以向个人保证，其预期的未来效用不会受到超过 exp(ε)≈(1+ε)exp(\\varepsilon) \\approx (1+\\varepsilon)exp(ε)≈(1+ε) 因子的损害。（注：由 exe^xex 的泰勒展开得到的近似值）注意，这个承诺独立于个人的是效用函数 ui(a)u_i(a)ui​(a)，同时适用于可能具有完全不同效用函数的多个人。 2.3.2 差分隐私不能保证什么 正如我们在吸烟导致癌症的例子中所看到的，尽管差分隐私是一个非常有力的保证，但它并不能保证无条件的免受伤害。它也不会在以前没有存在的地方创造隐私。更确切的说，差别隐私并不能保证一个人认为是自己秘密的东西仍然是秘密的。它只是确保一个人参与数据的发布本身不会被泄露，也不会导致泄露任何一个人参与的具体情况。从数据中得出的结论很可能反映了个人的统计信息。一项旨在发现特定疾病早期指标的健康调查可能会产生强有力的、甚至是结论性的结果；这些结论对于特定的个人来说并不是差分隐私被攻击的证据；这个人的个人信息甚至可能没有参与到数据集中（再次，差分隐私确保无论个人是否参与调查，这些结论性结果都以非常相似的概率获得。）特别是，如果调查告诉我们，特定的私人属性与公共可观察属性密切相关，那么这并不是对差分隐私的攻击，因为这种相同的相关性将以几乎相同的概率被观察到，而不受任何被调查者的存在或不存在的影响。 差分隐私的性质 引入并正式定义了差分隐私之后，我们将概括说明其关键的性质。 1.防范任意风险，防止个人数据被重新识别。 2.自动消除链接攻击，包括尝试使用所有过去，现在和将来的数据集以及其他形式和辅助信息源进行的所有攻击。 3.量化隐私损失。 差分隐私不是二元概念，它具有一定程度的隐私损失。这允许在不同技术之间进行比较：对于固定的隐私损失，哪种技术可以提供更好的准确性？ 对于固定的数据精度，哪种技术可以提供更好的隐私？ 4.差分隐私合成。也许最关键的是，损失的量化还允许对多次计算中的累积隐私损失进行分析和控制。了解合成下的差分隐私机制的行为，可以让我们从较简单的差分隐私构建块设计到分析复杂的差分隐私算法。 5.群隐私。差分隐私允许对诸如家庭之类的群体造成的隐私损失进行分析和控制。 6.后处理中的闭包差异隐私不受后处理的影响：数据分析师在没有其他有关隐私数据库的知识的情况下，无法计算差分隐私算法M \\mathcal{M}M 的输出函数，也就无法使其具有差分隐私性。也就是说，无论有什么辅助信息，无论是在形式上的定义上，还是在任何直觉上，数据分析师都无法通过简单地坐在角落里思考算法的输出来增加隐私损失。 这些是差分隐私的性质。我们可以证明这些性质可逆吗？ 也就是说，这些性质或其中的某些子集是否暗含差分隐私？差分隐私能否在这些方面被削弱并且仍然有意义？这些是悬而未决的问题。 2.3.3 定义注解 隐私的粒度。 应当仔细审查有关差分隐私的声明，以确保承诺的保密性级别。差分隐私保证即使修改数据库中的单个条目，算法的行为也将大致保持不变。但是，什么构成数据库中的单个条目？考虑例如采用图数据库。 这样的数据库可能会编码一个社交网络：每个个体 i∈[n]i \\in [n]i∈[n] 由图中的一个顶点表示，而个体之间的联系则由边表示。 我们可以在与个体相对应的粒度级别上考虑差分隐私：也就是说，我们可能要求差分隐私算法对从图中添加或删除任何顶点不敏感。这提供了强大的隐私保证，但实际上在图中添加删除节点可能会造成比想象中更大的影响。 单个顶点的添加或删除可以在图中最多添加或删除n条边。我们希望从图中学习到信息，但是去除n条边不敏感性可能导致无法学习到有效信息。 另一方面，我们可以在对应于边的粒度级别上考虑差分隐私，并要求我们的算法仅对从图中添加或删除单个或少量边不敏感。当然，这是较弱的保证，但对于某些目的可能仍然足够。非正式地讲，如果我们承诺在单个边缘级别上具有 ε\\varepsilonε- 差分隐私，那么任何数据分析人员都不能得出关于图中 1/ε1/\\varepsilon1/ε 边的任何子集的存在的任何结论。在某些情况下，大批社交联系人可能不会被视为敏感信息：例如，一个人可能没有必要隐藏一个事实，即他的大部分联系对象都是他所在城市或工作场所中的某个人，因为他的住所和住所他工作的地方是公共信息。另一方面，可能存在少数高度敏感的社会联系人（例如，潜在的新雇主或亲密朋友）。在这种情况下，边隐私应足以保护敏感信息，同时也能比顶点隐私数据得到更全面地分析。假设一个人的朋友少于 1/ε1/\\varepsilon1/ε ，边隐私将保护此类个人的敏感信息。 作为另一个示例，可以设计差分性私人电影推荐系统，以在单个电影的“事件”级别保护训练集中的数据，隐藏任何单个电影的观点/打分，而不是隐藏个人对于电影的热情。（如美国人对西部牛仔或血腥牛仔的热情），或对于“用户”级别数据来说，不隐藏个人整体观点和打分历史。 小ε\\varepsilonε差分隐私机制都很相像。当 ε\\varepsilonε 较小时，(ε,0)(\\varepsilon,0)(ε,0)- 差分隐私 断言，对于所有成对的相邻数据库 x,yx,yx,y和所有输出 ooo，对手无法根据观察 ooo 来区分哪个是真正的数据库。当 ε\\varepsilonε 较小时，未能成为(ε,0)(\\varepsilon,0)(ε,0)- 差分隐私没必要惊讶。例如，该机制可能是(2ε,0)(2\\varepsilon,0)(2ε,0)- 差分隐私。差分隐私的性质保证了具有不同但都很小的ε\\varepsilonε时，机制的表现是相似的。 但是 ε\\varepsilonε 设置多大的值算大？未能满足 (15,0)(15,0)(15,0)- 差分隐私仅表示存在相邻数据库，并且输出 ooo 的情况下，基于对数据库 x,yx,yx,y 的观察，输出 ooo 的概率大。而且ooo 的输出可能不太相同（这被 (ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私解决）；数据库xxx和yyy可能设计得很复杂，很可能出现在“现实世界”中；攻击者可能没有正确的辅助信息来识别已经发生了泄露的输出；攻击者也可能对数据库了解得不够多，无法确定其对称差异的值。因此，就像弱密码系统可能泄漏从消息的最低有效位到完整的解密密钥的任何东西一样，未能满足(ε,0)(\\varepsilon,0)(ε,0)- 或 (ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私可能导致从有效的无意义隐私泄露到整个数据库的完全泄漏。一个大的ε\\varepsilonε 以它自己的方式是大的。 (个人理解：作者对差分隐私定义进行深入分析，考虑到了隐私的细粒度问题，图数据库和个人推荐系统可以有不同的隐私级别。同时对于隐私预算的度量，给出了讲解。) 其他形式 除了数据库之外，我们的隐私机制 M\\mathcal{M}M 通常还会将一些辅助参数 www 作为输入。 例如，www 可以在数据库 xxx 上指定查询 qwq_wqw​ 或查询集合Qw\\mathcal{Q}_wQw​。 机制 M(w,x)\\mathcal{M}(w,x)M(w,x) 可能（分别）对 qw(x)q_w(x)qw​(x) 或 Qw\\mathcal{Q}_wQw​ 中某些或所有查询进行差分隐私响应。 对于所有 δ⩾0\\delta \\geqslant 0δ⩾0，我们说如果每个w,M(w,⋅)w,\\mathcal{M}(w,\\cdot)w,M(w,⋅) 都满足(ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私，则机制M(⋅,⋅)\\mathcal{M}(\\cdot,\\cdot)M(⋅,⋅) 满足 (ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私。 www 参数中可能包含的参数的另一个示例是控制 δ=δ(k)\\delta = \\delta(k)δ=δ(k) 应该多小的安全性参数 kkk。也就是说，对于所有 kkk ，M(k,⋅)\\mathcal{M}(k,\\cdot)M(k,⋅) 应该是 (ε,δ(k)(\\varepsilon,\\delta(k)(ε,δ(k)- 差分隐私的。通常，在本专论中，我们要求 δ\\deltaδ 在 kkk 中的作用可以忽略不计，即 δ=k−w(1)\\delta = k^{-w(1)}δ=k−w(1)。因此，我们认为 δ\\deltaδ 在密码学意义上较小，而 ε\\varepsilonε 通常被认为是中等较小的常数。 在辅助参数 www 指定集合 Qw={q:χn→R}\\mathcal{Q}_w=\\{q: \\chi^n \\to \\mathbb{R} \\}Qw​={q:χn→R} 的情况下，我们将机制 M\\mathcal{M}M 称为摘要生成器。摘要生成器输出一个（差分隐私）摘要 A\\mathcal{A}A，该摘要 A\\mathcal{A}A 可用于计算 Qw\\mathcal{Q}_wQw​ 中所有查询的答案。也就是说，我们需要有一个重构过程 RRR，以便对于指定查询 qv∈Qwq_v \\in \\mathcal{Q}_wqv​∈Qw​ 的每个输入 vvv，重构过程输出 R(A,v)∈RR(\\mathcal{A},v) \\in \\mathbb{R}R(A,v)∈R。通常，我们将要求高概率 M\\mathcal{M}M 产生一个摘要 A\\mathcal{A}A，以便使用 A\\mathcal{A}A 的重构过程可以计算出准确的答案。也就是说，对于全部或大部分（通过某种分布加权）查询 qv∈Qwq_v \\in \\mathcal{Q}_wqv​∈Qw​，误差 ∣R(A,v)−qv(x)∣|R(\\mathcal{A},v)-q_v(x)|∣R(A,v)−qv​(x)∣ 将受到限制。我们有时会滥用表示法，并参考重构过程，以实际查询 qqq（而不是其某些重新表示的 vvv ）作为输入，并输出R(A,q)R(\\mathcal{A},q)R(A,q)。 摘要的一个特殊情况是综合数据库。顾名思义，合成数据库的行与原始数据库的行具有相同的类型。合成数据库的优点是可以使用分析人员将在原始数据库上使用的相同软件进行分析，从而无需特殊的重构过程 RRR。 备注2.1 由于浮点数实现的微妙之处，在编程诸如 Laplace 机制之类的有价机制时，必须格外小心。否则，差分隐私可能会被破坏，因为数据库 xxx 上具有非零概率的输出由于四舍五入的缘故，相邻数据库 yyy 上的概率可能为零。这只是在差异性隐私的情况下需要仔细检查浮点实现的一种方式，并且它不是唯一的。 (个人理解：多参数的输入机制的引入对查询及其查询子集作出更多操作，其中机制 M(w,x)\\mathcal{M}(w,x)M(w,x) 中的参数要与 (ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私中的隐私预算区分开来。对于后面的摘要生成器我的理解是对原始数据集的差分隐私化处理，将结果重新映射到数据集上。这有待后期深入理解和学习。) Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-21 19:28:06 "},"2-Basic-Terms/Bibliographic-notes.html":{"url":"2-Basic-Terms/Bibliographic-notes.html","title":"参考文献","keywords":"","body":"参考文献 The definition of differential privacy is due to Dwork et al. [23]; the precise formulation used here and in the literature first appears in [20] and is due to Dwork and McSherry. The term “differential privacy” was coined by Michael Schroeder. The impossibility of semantic secu- rity is due to Dwork and Naor [25]. Composition and group privacy for (ε,0)-differentially private mechanisms is first addressed in [23].Composition for (ε,δ)-differential privacy was first addressed in [21] (but see the corrected proof in Appendix B, due to Dwork and Lei [22]). The vulnerability of differential privacy to inappropriate implementa- tions of floating point numbers was observed by Mironov, who proposed a mitigation [63]. Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-03 13:00:07 "},"3-Basic-Techniques-and-Composition-Theorems/Overview.html":{"url":"3-Basic-Techniques-and-Composition-Theorems/Overview.html","title":"三、基本技术与组成定理","keywords":"","body":"三、基本技术与组成定理 本章在回顾了一些概率工具之后，介绍了拉普拉斯机制，该机制为实际（向量）值的查询提供了差分隐私。这种应用自然引出指数机制，这是一种用于从一组离散的候选输出中进行差分隐私选择的方法。然后，我们分析了由多种差分隐私机制构成造成的累积隐私损失。最后，我们提供了一种方法——稀疏矢量技术——主要用于报告可能非常大量的计算结果，但前提是只有少数几个是“有意义的”。 在本节中，我们描述了差异隐私中的一些最基本的技术，我们将再次使用它们。此处描述的技术构成了我们将要开发的所有其他算法的基本组成部分。 Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-04 11:09:54 "},"3-Basic-Techniques-and-Composition-Theorems/Useful-probabilistic-tools.html":{"url":"3-Basic-Techniques-and-Composition-Theorems/Useful-probabilistic-tools.html","title":"概率工具","keywords":"","body":"3.1 概率工具 以下集中不等式经常会有用。 我们以易于使用的形式而不是最强的形式陈述它们。 （注：集中不等式：集中不等式是数学中的一类不等式，描述了一个随机变量是否集中在某个取值附近。例如大数定律说明了一系列独立同分布随机变量的平均值在概率上趋近于它们的数学期望，这表示随着变量数目增大，平均值会集中在数学期望附近。） 定理3.1（加法形式的切尔诺夫界限、又称切尔诺夫不等式）定义 X1,X2,...,XmX_1,X_2 ,...,X_mX1​,X2​,...,Xm​ 为独立随机变量，对任意,iii 有 0≤Xi≤10\\leq X_i \\leq 10≤Xi​≤1 。定义 S=1m∑i=1mXiS = \\frac{1}{m}\\sum_{i=1}^{m}X_iS=m1​∑i=1m​Xi​ 为随机变量的均值，定义 μ=E[S]\\mu = \\mathbb{E}[S]μ=E[S] 为他们的期望均值。则可以得到如下不等式： Pr[S>μ+ε]≤e−2mε2Pr[Sμ−ε]≤e−2mε2 \\begin{aligned} Pr[S > \\mu + \\varepsilon] &\\leq e^{-2m\\varepsilon^{2}}\\\\ Pr[S Pr[S>μ+ε]Pr[Sμ−ε]​≤e−2mε2≤e−2mε2​ 定理3.2（乘法形式的切尔诺夫不等式）定义 X1,X2,...,XmX_1,X_2 ,...,X_mX1​,X2​,...,Xm​ 为独立随机变量，对任意,iii 有 0≤Xi≤10\\leq X_i \\leq 10≤Xi​≤1 。定义 S=1m∑i=1mXiS = \\frac{1}{m}\\sum_{i=1}^{m}X_iS=m1​∑i=1m​Xi​ 为随机变量的均值，定义 μ=E[S]\\mu = \\mathbb{E}[S]μ=E[S] 为他们的期望均值。则可以得到如下不等式： Pr[S>(1+ε)μ]≤e−mμε2/3Pr[S(1−ε)μ]≤e−mμε2/2 \\begin{aligned} Pr[S > (1 + \\varepsilon)\\mu] &\\leq e^{-m\\mu\\varepsilon^{2}/3}\\\\ Pr[S Pr[S>(1+ε)μ]Pr[S(1−ε)μ]​≤e−mμε2/3≤e−mμε2/2​ 当我们没有独立的随机变量时。我们仍然可以应用 AzumaAzumaAzuma 不等式： 定理3.3 Azuma不等式 令 fff 为 mmm 个随机变量 X1,...,XmX_1,...,X_mX1​,...,Xm​ 的方法，每一个 XiX_iXi​ 的值取自集合 AiA_iAi​ ，使得 E(f)\\mathbb{E}(f)E(f) 有界。用 cic_ici​ 表示 XiX_iXi​ 对 fff 的最大影响，即对于所有的 ai,ai′∈Aia_i,a_i^{\\prime} \\in A_iai​,ai′​∈Ai​， 有： ∣E[f∣X1,...,Xi−1,Xi=ai]∣−∣E[f∣X1,...,Xi−1,Xi=ai′]∣≤ci |\\mathbb{E}[f|X_1,...,X_{i-1},X_i=a_i]|-|\\mathbb{E}[f|X_1,...,X_{i-1},X_i=a_i^\\prime]| \\leq c_i ∣E[f∣X1​,...,Xi−1​,Xi​=ai​]∣−∣E[f∣X1​,...,Xi−1​,Xi​=ai′​]∣≤ci​ 则： Pr[f(Xi,...,Xm)≥E[f]+t]≤exp(−2t2∑i=1mci2) Pr[f(X_i,...,X_m) \\geq \\mathbb{E}[f] + t ] \\leq exp(-\\frac{2t^2}{\\sum_{i=1}^{m}c_i^2}) Pr[f(Xi​,...,Xm​)≥E[f]+t]≤exp(−∑i=1m​ci2​2t2​) （注：Azuma不等式涉及随机过程中“鞅”（Martingale）的概念） 定理3.4 斯特林近似 n!n!n! 可以近似于 2nπ(n/e)n\\sqrt{2n\\pi}(n/e)^n2nπ​(n/e)n: 2nπ(n/e)ne1/(12n+1)n!2nπ(n/e)ne1/(12n) \\sqrt{2n\\pi}(n/e)^ne^{1/(12n+1)} 2nπ​(n/e)ne1/(12n+1)n!2nπ​(n/e)ne1/(12n) Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-05 19:04:29 "},"3-Basic-Techniques-and-Composition-Theorems/Randomized-response.html":{"url":"3-Basic-Techniques-and-Composition-Theorems/Randomized-response.html","title":"随机响应","keywords":"","body":"3.2 随机响应 让我们回想一下第2节中描述的用于评估非法行为发生频率的简单随机响应机制。 让XYZ成为这样的活动。 面对查询“您在过去一周内从事XYZ吗？”，指示受访者执行以下步骤： 1.掷硬币。 2.如果是反面，请如实回应。 3.如果是正面，那么再掷第二枚硬币，如果正面回答“是”，如果是反面则回答“否”。 随机响应背后的动机是，它提供了“合理的否认”。例如，可能提供了“是”响应，因为第一次和第二次硬币翻转都是正面，概率为1/4。换句话说，隐私是通过过程获得的，没有“好”或“坏”的响应。获得响应的过程会影响如何合理地解释它们。如下声明所示，这种随机响应是差分隐私的。 声明3.5 上述随机响应方法是 (ln3,0)(ln3,0)(ln3,0)- 差分隐私的。 【证明】： 假设固定随机响应者为同一人。上述分析表明 Pr[Response=Yes∣Truth=Yes]=3/4Pr[Response=Yes|Truth=Yes]=3/4Pr[Response=Yes∣Truth=Yes]=3/4 。具体来说，当事实是“是”时，如果第一个硬币出现反面（概率1/2）或第一个和第二个出现正面（概率1/4），则结果将是“是”，而 Pr[Response=Yes∣Truth=No]=1/4Pr[Response=Yes|Truth=No]=1/4Pr[Response=Yes∣Truth=No]=1/4 （第一个出现在正面，第二个出现反面；概率为1/4）。同理，将类似的推理应用于事实为“否”的情况，我们获得： Pr[Response=Yes∣Truth=Yes]Pr[Response=Yes∣Truth=No]=Pr[Response=No∣Truth=No]Pr[Response=No∣Truth=Yes]=3/41/4=3=exp(ln3) \\begin{aligned} \\frac{Pr[Response=Yes|Truth=Yes]}{Pr[Response=Yes|Truth=No]} \\\\ = \\frac{Pr[Response=No|Truth=No]}{Pr[Response=No|Truth=Yes]} &= \\frac{3/4}{1/4} = 3 = exp(ln3) \\end{aligned} Pr[Response=Yes∣Truth=No]Pr[Response=Yes∣Truth=Yes]​=Pr[Response=No∣Truth=Yes]Pr[Response=No∣Truth=No]​​=1/43/4​=3=exp(ln3)​ 于是  ε=ln3\\ \\varepsilon = ln3 ε=ln3 上述随机响应方法是 (ln3,0)(ln3,0)(ln3,0)- 差分隐私的。 Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-13 08:00:39 "},"3-Basic-Techniques-and-Composition-Theorems/The-laplace-mechanism.html":{"url":"3-Basic-Techniques-and-Composition-Theorems/The-laplace-mechanism.html","title":"Laplace机制","keywords":"","body":"3.3 Laplace 机制 数值查询是数据库最基础的数据查询类型，将其定义为：f:N∣χ∣→Rkf:\\mathbb{N}^{|\\chi|} \\to \\mathbb{R}^kf:N∣χ∣→Rk。这个查询将数据库映射成为k个真实值。将查询的ℓ1\\ell_1ℓ1​敏感度作为衡量我们对查询回答的准确程度的参数之一。 定义3.1 (ℓ1(\\ell_1(ℓ1​敏感度) 方法 f:N∣χ∣→Rkf:\\mathbb{N}^{|\\chi|} \\to \\mathbb{R}^kf:N∣χ∣→Rk 的 ℓ1\\ell_1ℓ1​敏感度为： Δf=max⁡x,y∈N∣χ∣,∣∣x−y∣∣1=1∣∣f(x)−f(y)∣∣1 \\Delta f = \\max_{x,y\\in\\mathbb{N}^{|\\chi|},||x-y||_1=1}||f(x)-f(y)||_1 Δf=x,y∈N∣χ∣,∣∣x−y∣∣1​=1max​∣∣f(x)−f(y)∣∣1​ 函数 fff 的 ℓ1\\ell_1ℓ1​ 敏感度反映了单体的数据在最坏情况下可以改变函数 fff 的程度，因此，直观地讲，为了隐藏单个人的参与，我们必须引入响应的不确定性。确实，我们将这种动机形式化：函数的敏感性为我们对输出施加多少扰动以保护隐私提供了一个上界。自然而然地，一种噪声分布可带来差分隐私。 定义3.2（拉普拉斯分布） 以0为中心，以 bbb 为尺度的拉普拉斯分布，其概率密度函数的分布为： Lap(x∣b)=12bexp(−∣x∣b) Lap(x|b) = \\frac{1}{2b}exp(-\\frac{|x|}{b}) Lap(x∣b)=2b1​exp(−b∣x∣​) 这个分布的方差是 σ2=2b2\\sigma^2=2b^2σ2=2b2 。我们有时会写 Lap(b)Lap(b)Lap(b) 来表示带尺度为 bbb 的Laplace分布，有时会滥用符号，写 Lap(b)Lap(b)Lap(b) 来表示随机变量 X∽Lap(b)X \\backsim Lap(b)X∽Lap(b)。 拉普拉斯分布是指数分布的对称版本。 我们现在定义拉普拉斯机制。顾名思义，拉普拉斯机制将简单地计算 fff，并用拉普拉斯分布的噪声扰动每个映射 fff 的输出结果(注：此处为个人理解补充进翻译中，原文省略了指代与解释。)。噪声的尺度将校准为 fff 的敏感度（除以 ε\\varepsilonε） [1]\\ ^{[1]} [1] （注[1]: 或者，使用方差校准为 Δfln(1/δ)/ε\\Delta fln(1/\\delta)/\\varepsilonΔfln(1/δ)/ε 的高斯噪声，可以实现 (ε,δ)(\\varepsilon,\\delta)(ε,δ)- 差分隐私（请参阅附录A）。拉普拉斯机制的使用更为简洁，两种机制在合成下的行为类似（定理3.20）） 定义3.3 （拉普拉斯机制） 给定任意方法 f:N∣χ∣→Rkf:\\mathbb{N}^{|\\chi|} \\to \\mathbb{R}^kf:N∣χ∣→Rk， 拉普拉斯机制定义为如下形式： ML(x,f(⋅),ε)=f(x)+(Y1,…,Yk) \\mathcal{M}_L(x,f(\\cdot),\\varepsilon)=f(x) + (Y_1,\\dots,Y_k) ML​(x,f(⋅),ε)=f(x)+(Y1​,…,Yk​) 此处的 YiY_iYi​ 是从 Lap(Δf/ε)Lap(\\Delta f/\\varepsilon)Lap(Δf/ε) 中提取的独立同分布随机变量。 定理 3.6 拉普拉斯机制是 (ε,0)(\\varepsilon,0)(ε,0)-差分隐私。 【证明】：设 x∈N∣χ∣,y∈N∣χ∣x \\in \\mathbb{N}^{|\\chi|},y \\in \\mathbb{N}^{|\\chi|}x∈N∣χ∣,y∈N∣χ∣，同时满足 ∣∣x−y∣∣1≤1||x-y||_1 \\leq 1∣∣x−y∣∣1​≤1 （即两者为相邻数据集）。并设 f(⋅)f(\\cdot)f(⋅) 是函数 f:N∣χ∣→Rkf:\\mathbb{N}^{|\\chi|} \\to \\mathbb{R}^kf:N∣χ∣→Rk。用 pxp_xpx​ 表示概率密度函数 ML(x,f,ε)\\mathcal{M}_L(x,f,\\varepsilon)ML​(x,f,ε), pyp_ypy​ 表示概率密度函数 ML(y,f,ε)\\mathcal{M}_L(y,f,\\varepsilon)ML​(y,f,ε)。我们用任意点 zzz 比较这两者的概率密度： px(z)py(z)=∏i=1k(exp(−ε∣f(x)i−zi∣Δf)exp(−ε∣f(y)i−zi∣Δf))=∏i=1kexp(ε(∣f(y)i−zi∣−∣f(x)i−zi∣)Δf)≤∏i=1kexp(ε∣f(x)i−f(y)i∣Δf)=exp(ε∣∣f(x)−f(y)∣∣1Δf)≤exp(ε) \\begin{aligned} \\frac{p_x(z)}{p_y(z)} &= \\prod_{i=1}^{k}\\Bigg(\\frac{exp(-\\frac{\\varepsilon|f(x)_i-z_i|}{\\Delta f})}{exp(-\\frac{\\varepsilon|f(y)_i-z_i|}{\\Delta f})} \\Bigg)\\\\ &= \\prod_{i=1}^{k}exp\\Bigg( \\frac{\\varepsilon(|f(y)_i-z_i|-|f(x)_i-z_i|)}{\\Delta f} \\Bigg)\\\\ &\\leq \\prod_{i=1}^{k}exp\\Bigg(\\frac{\\varepsilon|f(x)_i-f(y)_i|}{\\Delta f} \\Bigg)\\\\ &= exp\\Bigg(\\frac{\\varepsilon||f(x)-f(y)||_1}{\\Delta f} \\Bigg)\\\\ &\\leq exp(\\varepsilon) \\end{aligned} py​(z)px​(z)​​=i=1∏k​(exp(−Δfε∣f(y)i​−zi​∣​)exp(−Δfε∣f(x)i​−zi​∣​)​)=i=1∏k​exp(Δfε(∣f(y)i​−zi​∣−∣f(x)i​−zi​∣)​)≤i=1∏k​exp(Δfε∣f(x)i​−f(y)i​∣​)=exp(Δfε∣∣f(x)−f(y)∣∣1​​)≤exp(ε)​ 第一个不等式由三角不等式推导得来，最后一个不等式是由敏感度定义得到，即：∣∣x−y∣∣1≤1||x-y||_1 \\leq 1∣∣x−y∣∣1​≤1。且由对称性可得 px(z)py(z)≥exp(−ε)\\frac{p_x(z)}{p_y(z)} \\geq exp(-\\varepsilon)py​(z)px​(z)​≥exp(−ε)。 【补充1: px(z)py(z)=∏i=1k(exp(−ε∣f(x)i−zi∣Δf)exp(−ε∣f(y)i−zi∣Δf))\\frac{p_x(z)}{p_y(z)} = \\prod_{i=1}^{k}\\Big(\\frac{exp(-\\frac{\\varepsilon|f(x)_i-z_i|}{\\Delta f})}{exp(-\\frac{\\varepsilon|f(y)_i-z_i|}{\\Delta f})} \\Big)py​(z)px​(z)​=∏i=1k​(exp(−Δfε∣f(y)i​−zi​∣​)exp(−Δfε∣f(x)i​−zi​∣​)​) 表示形式是拉普拉斯分布的分量形式，即：px(z)=ε2Δf∏i=1kexp(ε(∣f(y)i−zi∣−∣f(x)i−zi∣)Δf)p_x(z)= \\frac{\\varepsilon}{2\\Delta f}\\prod_{i=1}^{k}exp\\Big(\\frac{\\varepsilon(|f(y)_i-z_i|-|f(x)_i-z_i|)}{\\Delta f}\\Big)px​(z)=2Δfε​∏i=1k​exp(Δfε(∣f(y)i​−zi​∣−∣f(x)i​−zi​∣)​) 亦即：px(z→)=ε2Δfexp(ε(∣f(y)−z→∣−∣f(x)−z→∣)Δf)p_x(\\overrightarrow{z})= \\frac{\\varepsilon}{2\\Delta f}exp\\Big(\\frac{\\varepsilon(|f(y)-\\overrightarrow{z}|-|f(x)-\\overrightarrow{z}|)}{\\Delta f}\\Big)px​(z)=2Δfε​exp(Δfε(∣f(y)−z∣−∣f(x)−z∣)​) 】 【补充2：由于 定义 2.3 (数据库之间距离) 定义了数据库 xxx 和 yyy 之间的 ℓ1\\ell_1ℓ1​ 距离为 ∣∣x−y∣∣1||x-y||_1∣∣x−y∣∣1​ ∣∣x−y∣∣1=∑i=1∣χ∣∣xi−yi∣ ||x-y||_1 = \\sum_{i=1}^{|\\chi|}|x_i-y_i| ∣∣x−y∣∣1​=i=1∑∣χ∣​∣xi​−yi​∣ 故：上述证明中的 ∏i=1kexp(ε∣f(x)i−f(y)i∣Δf)=exp(ε∣∣f(x)−f(y)∣∣1Δf)\\prod_{i=1}^{k}exp\\Big(\\frac{\\varepsilon|f(x)_i-f(y)_i|}{\\Delta f} \\Big)=exp\\Big(\\frac{\\varepsilon||f(x)-f(y)||_1}{\\Delta f} \\Big)∏i=1k​exp(Δfε∣f(x)i​−f(y)i​∣​)=exp(Δfε∣∣f(x)−f(y)∣∣1​​) 可由如下步骤得到： ∏i=1kexp(ε∣f(x)i−f(y)i∣Δf)=exp(ε∑i=1k∣f(x)i−f(y)i∣Δf)=exp(ε∣∣f(x)−f(y)∣∣1Δf) \\begin{aligned} \\prod_{i=1}^{k}exp\\Bigg(\\frac{\\varepsilon|f(x)_i-f(y)_i|}{\\Delta f} \\Bigg) &= exp\\Bigg(\\frac{\\varepsilon\\sum_{i=1}^{k}|f(x)_i-f(y)_i|}{\\Delta f} \\Bigg)\\\\ &= exp\\Bigg(\\frac{\\varepsilon||f(x)-f(y)||_1}{\\Delta f} \\Bigg) \\end{aligned} i=1∏k​exp(Δfε∣f(x)i​−f(y)i​∣​)​=exp(Δfε∑i=1k​∣f(x)i​−f(y)i​∣​)=exp(Δfε∣∣f(x)−f(y)∣∣1​​)​ 】 例3.1 计数查询：计数查询是“数据库中有多少个元素满足属性 P？”形式的查询。我们将一次又一次地回到这些查询，有时是纯形式，有时使用小数形式返回这些查询（“数据库中元素的分数是多少....？”），有时带有权重（线性查询），有时带有稍微复杂的形式。（例如，对数据库中的每个元素应用 h:N∣χ∣→[0,1]h:\\mathbb{N}^{|\\chi|} \\to [0,1]h:N∣χ∣→[0,1] 并求和）。计数是一个非常强大的原语。它占据了统计查询学习模型中所有可学习的内容，以及许多标准的数据挖掘任务和基本统计​​信息。由于计数查询的敏感度为1（单个人的添加或删除最多可以将计数更改为1），因此 定理3.6 的直接结果是，可以实现 (ε,0)(\\varepsilon,0)(ε,0)-差分隐私 计数通过添加尺度参数为 1/ε1/\\varepsilon1/ε 的噪声进行查询，即通过添加从 Lap(1/ε)Lap(1/\\varepsilon)Lap(1/ε) 分布提取的噪声进行查询。预期的失真或错误为 1/ε1/\\varepsilon1/ε，与数据库的大小无关。 固定但任意数量的 mmm 个计数查询列表可以视为向量值查询。缺少有关查询集的任何进一步信息时，此矢量值查询的敏感性的最坏情况范围是 mmm，因为单个个体可能会更改每个计数（敏感度为 mmm）。在这种情况下，可以通过将尺度参数为 m/εm/\\varepsilonm/ε 的噪声添加到每个查询的真实答案中来实现 (ε,0)(\\varepsilon,0)(ε,0)-差分隐私。 有时我们将响应大量（可能是任意的）查询的问题称为查询发布问题。 例3.2 直方图查询：在查询在结构上不相交的特殊（但很常见）情况下，我们可以做得更好——我们不必让噪声随查询的数量而变化。直方图查询就是一个例子。在这种类型的查询中，数据整体（ N∣χ∣\\mathbb{N}^{|\\chi|}N∣χ∣ ）被划分为多个单元格，查询每个单元格中有多少数据库元素。由于单元格是不相交的，单个数据库元素的添加或删除会影响一个单元格中的计数，并且与该单元格的差异是 1，因此直方图查询的敏感度为1，可以对每个单元格中的真实计数增加源自 Lap(1/ε)Lap(1/\\varepsilon)Lap(1/ε) 分布的噪声来回答查询。 为了了解一般查询的 Laplace 机制的准确性，我们使用以下有用的事实： 事实 3.7： 如果 Y∽Lap(b)Y \\backsim Lap(b)Y∽Lap(b)，则： Pr[∣Y∣≥t⋅b]=exp(−t) Pr[|Y| \\geq t \\cdot b] = exp(-t) Pr[∣Y∣≥t⋅b]=exp(−t) 这个事实与布尔不等式（译者注：Union Bound，又称 Boole’s Inequality1>^{}1>）一起为我们提供了一个 关于拉普拉斯机制准确性的简单不等式： 定理 3.8 ：设 f:N∣χ∣→Rk,y=ML(x,f(⋅),ε)f:\\mathbb{N}^{|\\chi|} \\to \\mathbb{R}^k,y=\\mathcal{M}_L(x,f(\\cdot),\\varepsilon)f:N∣χ∣→Rk,y=ML​(x,f(⋅),ε)。则 ∀δ∈(0,1]\\forall\\delta \\in (0,1]∀δ∈(0,1]： Pr[∣∣f(x)−y∣∣∞≥ln⁡(kδ)⋅(Δfε)]≤δ Pr\\Big[||f(x)-y||_\\infty \\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon}) \\Big] \\leq \\delta Pr[∣∣f(x)−y∣∣∞​≥ln(δk​)⋅(εΔf​)]≤δ 【证明】 我们有： Pr[∣∣f(x)−y∣∣∞≥ln⁡(kδ)⋅(Δfε)]=Pr[max⁡i∈[k]∣Yi∣≥ln⁡(kδ)⋅(Δfε)]≤k⋅Pr[∣Yi∣≥ln⁡(kδ)⋅(Δfε)]=k⋅(δk)=δ \\begin{aligned} Pr\\Big[||f(x)-y||_\\infty \\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon})\\Big] &= Pr\\Big[\\max_{i \\in [k]}|Y_i|\\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon}) \\Big]\\\\ & \\leq k\\cdot Pr\\Big[|Y_i|\\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon}) \\Big] \\\\ &= k\\cdot(\\frac{\\delta}{k})\\\\ &= \\delta \\end{aligned} Pr[∣∣f(x)−y∣∣∞​≥ln(δk​)⋅(εΔf​)]​=Pr[i∈[k]max​∣Yi​∣≥ln(δk​)⋅(εΔf​)]≤k⋅Pr[∣Yi​∣≥ln(δk​)⋅(εΔf​)]=k⋅(kδ​)=δ​ 在证明中，第二个和最后的不等式是从拉普拉斯分布和事实3.7中推导得到的。 （译者注 布尔不等式：指对于全部事件的概率不大于单个事件的概率总和，对于事件 A1,A2,A3...:P(⋃iAi)≤∑iP(Ai)A_1,A_2,A_3...: P(\\bigcup_{i}A_i)\\leq \\sum_iP(A_i)A1​,A2​,A3​...:P(⋃i​Ai​)≤∑i​P(Ai​)） 【补充3：上一证明过程缺少 ℓ∞\\ell_\\inftyℓ∞​ 范数距离，又称切比雪夫距离，如下定义：∣∣x∣∣||x||∣∣x∣∣为xxx向量各个元素绝对值最大那个元素的绝对值，形式化为： ∣∣x∣∣∞=lim⁡k→∞(∑i=1n∣pi−qi∣k)1/k=max⁡i∈[k]∣pi−qi∣ ||x||_{\\infty}=\\lim\\limits_{k \\to \\infty}\\Big(\\sum_{i=1}^n|p_i-q_i|^k \\Big)^{1/k}=\\max_{i \\in [k]}|p_i-q_i| ∣∣x∣∣∞​=k→∞lim​(i=1∑n​∣pi​−qi​∣k)1/k=i∈[k]max​∣pi​−qi​∣ 】 【补充4: （定理3.8补充证明） 由 Laplace 机制可知 Yi∽Lap(Δf/ε)Y_i \\backsim Lap(\\Delta f/\\varepsilon)Yi​∽Lap(Δf/ε) 和 y=ML(x,f(⋅ε)=f(x)+(Y1,…,Yk)y=\\mathcal{M}_L(x,f(\\cdot\\varepsilon)=f(x) + (Y_1,\\dots,Y_k)y=ML​(x,f(⋅ε)=f(x)+(Y1​,…,Yk​)，则: ∣f(x)−y∣=∣(Y1,...Yk)∣|f(x) - y|= |(Y_1,...Y_k)|∣f(x)−y∣=∣(Y1​,...Yk​)∣。 又因切比雪夫距离定义： ∣∣f(x)−y∣∣∞=maxi∈k∣f(x)−y∣=maxi∈k∣Yi∣||f(x)-y||_\\infty=max_{i \\in k}|f(x)-y|=max_{i \\in k}|Y_i|∣∣f(x)−y∣∣∞​=maxi∈k​∣f(x)−y∣=maxi∈k​∣Yi​∣， 故证明的第一步可以由此推导出： Pr[∣∣f(x)−y∣∣∞≥ln⁡(kδ)⋅(Δfε)]=Pr[max⁡i∈[k]∣Yi∣≥ln⁡(kδ)⋅(Δfε)]Pr\\Big[||f(x)-y||_\\infty \\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon})\\Big] = Pr\\Big[\\max_{i \\in [k]}|Y_i|\\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon}) \\Big]Pr[∣∣f(x)−y∣∣∞​≥ln(δk​)⋅(εΔf​)]=Pr[maxi∈[k]​∣Yi​∣≥ln(δk​)⋅(εΔf​)] 证明第二步是因为 max⁡i∈[k]∣Yi∣≥ln⁡(kδ)⋅(Δfε)\\max_{i \\in [k]}|Y_i| \\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon})maxi∈[k]​∣Yi​∣≥ln(δk​)⋅(εΔf​) 的概率必然小于等于 ⋃i{∣Yi∣≥ln⁡(kδ)⋅(Δfε)}\\bigcup_{i} \\{|Y_i| \\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon})\\}⋃i​{∣Yi​∣≥ln(δk​)⋅(εΔf​)} 全体的概率，且由布尔不等式推导而来，即最大值 YiY_iYi​ 概率不大于单个事件的概率总和。又因为 事实3.7，推导如下： Pr[max⁡i∈[k]∣Yi∣≥ln⁡(kδ)⋅(Δfε)]≤Pr[⋃i{∣Yi∣≥ln⁡(kδ)⋅(Δfε)}]≤∑ik⋅Pr[∣Yi∣≥ln⁡(kδ)⋅(Δfε)]=∑ik⋅exp(−ln(kδ))=k⋅(δk)=δ \\begin{aligned} Pr\\Big[\\max_{i \\in [k]}|Y_i|\\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon})\\Big] & \\leq Pr\\Big[ \\bigcup_{i} \\{|Y_i| \\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon}) \\}\\Big]\\\\ &\\leq \\sum_i^k \\cdot Pr\\Big[|Y_i| \\geq \\ln(\\frac{k}{\\delta})\\cdot(\\frac{\\Delta f}{\\varepsilon})\\Big]\\\\ &= \\sum_i^k \\cdot exp\\big(-ln(\\frac{k}{\\delta})\\big)\\\\ &= k\\cdot(\\frac{\\delta}{k})\\\\ &= \\delta \\end{aligned} Pr[i∈[k]max​∣Yi​∣≥ln(δk​)⋅(εΔf​)]​≤Pr[i⋃​{∣Yi​∣≥ln(δk​)⋅(εΔf​)}]≤i∑k​⋅Pr[∣Yi​∣≥ln(δk​)⋅(εΔf​)]=i∑k​⋅exp(−ln(δk​))=k⋅(kδ​)=δ​ 】 例3.3 名字频度： 假设我们要使用 2010 年人口普查参与者数据，并从数据中统计出给定的 10,000 个名字里各个名字的频度。 这个问题可以用查询 f:N∣χ∣→R10000f:\\mathbb{N}^{|\\chi|} \\to \\mathbb{R}^{10000}f:N∣χ∣→R10000 表示。 这是一个直方图查询，因此灵敏度Δf=1\\Delta f = 1Δf=1 ，因为每个人最多只能有一个名字。当频度查询是 (1,0)(1,0)(1,0)- 差分隐私的，并且概率要为 95％ ，我们使用上面的定理可以计算所有10,000名字的频度，其估计的相加误差不会超过 ln⁡(10000/0.05)≈12.2\\ln (10000/0.05) \\thickapprox 12.2ln(10000/0.05)≈12.2。 对于一个人口超过 300,000,000 的国家来说，这是非常低的错误！ 【补充5: 由例3.3可知：k=10000,Δf=1,ε=1,δ=1−0.95=0.05k=10000,\\Delta f = 1,\\varepsilon=1,\\delta = 1 - 0.95 = 0.05k=10000,Δf=1,ε=1,δ=1−0.95=0.05，并由定理3.8可以推得上述结论： Pr[max⁡i∈[10000]∣Yi∣≥ln⁡(100000.05)⋅(11)]≤0.05then   Pr[max⁡i∈[10000]∣Yi∣≤ln⁡(100000.05)⋅(11)]≥1−0.05Pr[max⁡i∈[10000]∣Yi∣≤ln⁡(100000.05)]≥0.95 \\begin{aligned} Pr\\Big[\\max_{i \\in [10000]}|Y_i|\\geq \\ln(\\frac{10000}{0.05})\\cdot(\\frac{1}{1})\\Big] &\\leq 0.05\\\\ then \\ \\ \\ Pr\\Big[\\max_{i \\in [10000]}|Y_i| \\leq \\ln(\\frac{10000}{0.05})\\cdot(\\frac{1}{1})\\Big] &\\geq 1 - 0.05\\\\ Pr\\Big[\\max_{i \\in [10000]}|Y_i| \\leq \\ln(\\frac{10000}{0.05})\\Big] &\\geq 0.95 \\end{aligned} Pr[i∈[10000]max​∣Yi​∣≥ln(0.0510000​)⋅(11​)]then   Pr[i∈[10000]max​∣Yi​∣≤ln(0.0510000​)⋅(11​)]Pr[i∈[10000]max​∣Yi​∣≤ln(0.0510000​)]​≤0.05≥1−0.05≥0.95​ 】 差分隐私选择 例3.3中的任务是一个差分隐私选择：输出空间是离散的，任务是产生一个“最佳”答案。在例3.3中是选择输出是常用名频度最多的直方图单元。 例3.4 最常见的医学疾病 假设我们希望知道哪一个疾病是在一组被调查者的医疗史中最常见的，因此，需要对这些调查者进行一系列调查，调查其个人是否曾经接受过这些疾病的诊断。由于个人可能得过许多疾病，所以这些调查的敏感性可能很高。尽管如此，正如我们接下来描述的，这个任务可以通过在每个计数中添加 Lap(1/ε)Lap(1/\\varepsilon)Lap(1/ε) 噪声来解决（注意噪声的小范围，它独立于疾病的总数）。关键是 mmm 个噪音计数本身不会被发布（尽管“获胜”计数可以释放，没有额外的隐私损失）。（个人理解：m 个噪音计数即存在 m 种常见疾病，需要对 m 个常见疾病的统计计数增加噪声，并返回增加完噪声之后的最大值，即最常见的疾病。原文中的“获胜”应该指的是增加噪声最后的最大值。因为增加噪声之前与之后的最大值可能不一致。） Report Noisy Max 请考虑以下简单算法，目的是为了确定在 m 个计数查询中哪个具有最高数值：将独立生成的拉普拉斯噪声 Lap(1/ε)Lap(1/\\varepsilon)Lap(1/ε) 添加到每个计数中，并返回增加完噪声后最大计数索引（我们忽略之间可能的关联）。将此算法称为 Report Noisy Max。 注意到 “Report Noisy Max” 算法中的“信息最小化”原理：仅公开与最大值相对应的索引，而不是发布所有噪声计数并让分析人员找到最大值及其索引。 由于一个人的数据会影响所有计数，因此计数向量具有较高的 ℓ1\\ell_1ℓ1​ 灵敏度，即 Δf=m\\Delta f = mΔf=m，如果我们想使用拉普拉斯机制发布所有计数，则需要更多的噪声。 声明3.9 Report Noisy Max 算法是 (ε,0)(\\varepsilon,0)(ε,0)-差分隐私。 【证明】 令 D=D′∪{a}D=D' \\cup \\{a\\}D=D′∪{a} 。 令 c,c′c,c'c,c′ 分别表示数据库为 D,D′D,D'D,D′的计数向量。我们使用两个属性： 1.计数的单调性。对于所有 j∈[m],cj≥cj′j \\in [m],c_j \\geq c'_jj∈[m],cj​≥cj′​ 2.利普希茨（Lipschitz）属性。对于所有 j∈[m],cj′+1≥cjj \\in [m],c'_j + 1 \\geq c_jj∈[m],cj′​+1≥cj​（注：Lipschitz连续，要求函数图像的曲线上任意两点连线的斜率一致有界，就是任意的斜率都小于同一个常数，这个常数就是 Lipschitz 常数，此处Lipschitz常数为1。） 定义任意 i∈[m]i \\in [m]i∈[m]，我们将限制 i 分别从 DDD 或 D′D'D′ 提取比率的上下界。 定义 r−ir_{-i}r−i​，从 Lap(1/ε)m−1Lap(1/\\varepsilon)^{m-1}Lap(1/ε)m−1 用于除第 i 个计数外的所有噪声计数。我们会单独讨论每个 r−ir_{-i}r−i​。我们使用符号 Pr[i∣ξ]Pr[i|\\xi]Pr[i∣ξ] 表示 Report Noisy Max 算法在以 ξ\\xiξ 的条件下，输出为 i 的概率。 我们首先讨论 Pr[i∣D,r−i]≤eεPr[i∣D′,r−i]Pr[i|D,r_{-i}] \\leq e^{\\varepsilon}Pr[i|D',r_{-i}]Pr[i∣D,r−i​]≤eεPr[i∣D′,r−i​] 的情况。 定义： r∗=min⁡ri:ci+ri>cj+rj ∀j≠i r^* = \\min_{r_i}:c_i + r_i > c_j + r_j \\ \\forall j \\neq i r∗=ri​min​:ci​+ri​>cj​+rj​ ∀j≠i 注意，上面已经定义了 r−ir_{-i}r−i​ 的情况。当且仅当 ri≥r∗r_i \\geq r^*ri​≥r∗ 时， i 为数据库 DDD 的最大统计噪声输出。 对于所有 1≤j̸=i≤m1 \\leq j \\not ={i} \\leq m1≤j̸=i≤m： ci+r∗>cj+rj⟹(1+ci′)+r∗≥ci+r∗>cj+rj≥cj′+rj⟹ci′+(r∗+1)>cj′+rj \\begin{aligned} c_i + r^* &> c_j + r_j\\\\ \\implies (1 + c'_i) + r^* \\geq c_i + r^* &> c_j + r_j \\geq c'_j + r_j\\\\ \\implies c'_i + (r^* + 1) &> c'_j + r_j \\end{aligned} ci​+r∗⟹(1+ci′​)+r∗≥ci​+r∗⟹ci′​+(r∗+1)​>cj​+rj​>cj​+rj​≥cj′​+rj​>cj′​+rj​​ 因此，如果 ri≥r∗+1r_i \\geq r^* + 1ri​≥r∗+1 ，则当数据库为 D' 时，第 i 个统计计数是最大的，且噪声向量为 (ri,r−i)(r_i,r_{-i})(ri​,r−i​)。下面的概率取决于 ri∽Lap(1/ε)r_i \\backsim Lap(1/\\varepsilon)ri​∽Lap(1/ε) 的选择。 Pr[ri≥1+r∗]≥e−εPr[ri≥r∗]=e−εPr[i∣D,r−i]⟹Pr[i∣D′,r−i]≥Pr[ri≥1+r∗]≥e−εPr[ri≥r∗]=e−εPr[i∣D,r−i] \\begin{aligned} Pr[r_i \\geq 1 + r^*] &\\geq e^{-\\varepsilon}Pr[r_i \\geq r^*] = e^{-\\varepsilon}Pr[i|D,r_{-i}]\\\\ \\implies Pr[i|D',r_{-i}] \\geq Pr[r_i \\geq 1 + r^*] &\\geq e^{-\\varepsilon}Pr[r_i \\geq r^*] = e^{-\\varepsilon}Pr[i|D,r_{-i}] \\end{aligned} Pr[ri​≥1+r∗]⟹Pr[i∣D′,r−i​]≥Pr[ri​≥1+r∗]​≥e−εPr[ri​≥r∗]=e−εPr[i∣D,r−i​]≥e−εPr[ri​≥r∗]=e−εPr[i∣D,r−i​]​ 上面等式两边乘上 eεe^{\\varepsilon}eε 第一种情况证明完毕。 证明第二种情况，即 Pr[i∣D′,r−i]≤eεPr[i∣D,r−i]Pr[i|D',r_{-i}] \\leq e^{\\varepsilon}Pr[i|D,r_{-i}]Pr[i∣D′,r−i​]≤eεPr[i∣D,r−i​] 定义： r∗=min⁡ri:ci′+ri>cj′+rj ∀j≠i r^* = \\min_{r_i}:c'_i + r_i > c'_j + r_j \\ \\forall j \\neq i r∗=ri​min​:ci′​+ri​>cj′​+rj​ ∀j≠i 注意，上面已经定义了 r−ir_{-i}r−i​ 的情况。当且仅当 ri≥r∗r_i \\geq r^*ri​≥r∗ 时， i 为数据库 DDD 的最大统计噪声输出。 对于所有 1≤j̸=i≤m1 \\leq j \\not ={i} \\leq m1≤j̸=i≤m： ci′+r∗>cj+rj⟹1+ci′+r∗>1+cj′+rj⟹ci′+(r∗+1)>(1+cj′)+rj⟹ci+(r∗+1)≥ci′+(r∗+1)>(1+cj′)+rj≥cj+rj \\begin{aligned} c'_i + r^* &> c_j + r_j\\\\ \\implies 1 + c'_i + r^* &> 1 + c'_j + r_j\\\\ \\implies c'_i + (r^* + 1) &> (1 + c'_j) + r_j\\\\ \\implies c_i + (r^* + 1) \\geq c'_i + (r^* + 1) &> (1 + c'_j) + r_j \\geq c_j + r_j\\\\ \\end{aligned} ci′​+r∗⟹1+ci′​+r∗⟹ci′​+(r∗+1)⟹ci​+(r∗+1)≥ci′​+(r∗+1)​>cj​+rj​>1+cj′​+rj​>(1+cj′​)+rj​>(1+cj′​)+rj​≥cj​+rj​​ 因此，如果 ri≥r∗+1r_i \\geq r^* + 1ri​≥r∗+1 ，则当数据库为 D 时，第 i 个统计计数是最大的，且噪声向量为 (ri,r−i)(r_i,r_{-i})(ri​,r−i​)。下面的概率取决于 ri∽Lap(1/ε)r_i \\backsim Lap(1/\\varepsilon)ri​∽Lap(1/ε) 的选择。 Pr[i∣D,r−i]≥Pr[ri≥r∗+1]≥e−εPr[ri≥r∗]=e−εPr[i∣D′,r−i] \\begin{aligned} Pr[i|D,r_{-i}] \\geq Pr[r_i \\geq r^* + 1 ] \\geq e^{-\\varepsilon}Pr[r_i \\geq r^*] = e^{-\\varepsilon}Pr[i|D',r_{-i}] \\end{aligned} Pr[i∣D,r−i​]≥Pr[ri​≥r∗+1]≥e−εPr[ri​≥r∗]=e−εPr[i∣D′,r−i​]​ 上面等式两边乘上 eεe^{\\varepsilon}eε 第二种情况证明完毕。 Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-14 19:19:43 "},"3-Basic-Techniques-and-Composition-Theorems/The-exponential-mechanism.html":{"url":"3-Basic-Techniques-and-Composition-Theorems/The-exponential-mechanism.html","title":"Exponential机制","keywords":"","body":"3.4 指数机制 我们在“最常见的名称”和“最常见的疾病”例子中，提到了响应的“效用”（名称或医疗疾病），在响应中我们使用拉普拉斯噪声估计了计数，并报告了噪声最大值。在这两个示例中，响应的效用都与生成的噪声值直接相关。也就是说，我们应使用与噪声大小相同的标度和相同的单位对名称或疾病的普遍程度进行适当地测量。 指数机制是为我们希望选择“最佳”响应而设计的，但将噪声直接添加到计算量可以完全破坏其价值，例如在拍卖中设定价格，目标是使收入最大化，但在最优价格中加入少量的正噪声（为了保护出价的隐私）可能会导致显著减少由此产生的收入，如下南瓜竞拍例子。 例 3.5（南瓜竞拍） 假设我们有大量的南瓜和四个竞标者：A，F，I，K，其中A，F，I分别出价1.00美元和K出价3.01美元，最优价格是多少？在 3.01美元时，收入为 3.01美元（只符合K的价格，故只有K买，收入3.01美元）；在 3.00美元 和 1.00美元 时候，收入为 3.00美元（只有A、F、I符合价格，收入共3美元）；但在 3.02美元时，收入为零（无人符合价格）！ 指数机制是使用任意效用函数（任意非数字范围）回答查询的自然构建块，同时保留了差异隐私。给定任意范围 R\\mathcal{R}R，将指数机制定义为某些效用函数 u:N∣χ∣×R→Ru:\\mathbb{N}^{|\\chi|} \\times \\mathcal{R} \\to \\mathbb{R}u:N∣χ∣×R→R，它将数据库输出对映射到效用分数。直观地讲，对于固定的数据库 xxx，用户更喜欢该机制输出 R\\mathcal{R}R 的某些元素具有最大的效用得分。请注意，当我们谈论效用分数 u:N∣χ∣×R→Ru:\\mathbb{N}^{|\\chi|} \\times \\mathcal{R} \\to \\mathbb{R}u:N∣χ∣×R→R 的敏感度时，我们只关心 uuu 相对于其数据库参数的敏感性；效用函数 uuu 可以是任意敏感的： Δu=max⁡r∈R max⁡x,y:∣∣x−y∣∣1≤1∣u(x,r)−u(y,r)∣ \\Delta u = \\max_{r \\in \\mathcal{R}} \\ \\max_{x,y:||x-y||_1 \\leq 1}|u(x,r)-u(y,r)| Δu=r∈Rmax​ x,y:∣∣x−y∣∣1​≤1max​∣u(x,r)−u(y,r)∣ 从直观上来看指数机制，其思想是输出每个可能的 r∈Rr \\in \\mathcal{R}r∈R ，其概率与 exp⁡(εu(x,r)/Δu)\\exp(\\varepsilon u(x,r)/\\Delta u)exp(εu(x,r)/Δu) 成正比，这样隐私损失才能约为： ln⁡(exp⁡(εu(x,r)/Δu)exp⁡(εu(y,r)/Δu))=ε[u(x,r)−u(y,r)]/Δu≤ε \\ln \\Big(\\frac{\\exp(\\varepsilon u(x,r)/\\Delta u)}{\\exp(\\varepsilon u(y,r)/\\Delta u)}\\Big)=\\varepsilon[u(x,r)-u(y,r)]/\\Delta u \\leq \\varepsilon ln(exp(εu(y,r)/Δu)exp(εu(x,r)/Δu)​)=ε[u(x,r)−u(y,r)]/Δu≤ε （注：此处原文公式有误，翻译为更正后的公式） (个人理解：根据效用函数敏感度 Δu\\Delta uΔu 的定义可知，数据库 x,yx,yx,y 是相邻数据库，相差为 1，则可以构造构造一个机制，将效用得分和与输出概率关联，使得满足 ε\\varepsilonε-差分隐私定义的隐私损失。由 2.3节中的隐私损失（机制质量) 可得出：当机制正比于 exp⁡(εu(x,r)/Δu),(Pr[M(x)=ξ]∝exp⁡(εu(x,r)/Δu))\\exp(\\varepsilon u(x,r)/\\Delta u),(Pr\\lbrack \\mathcal{M}(x) = \\xi \\rbrack \\propto \\exp(\\varepsilon u(x,r)/\\Delta u))exp(εu(x,r)/Δu),(Pr[M(x)=ξ]∝exp(εu(x,r)/Δu))， 该机制的隐私损失是 ε\\varepsilonε LM(x)∣∣M(y)(ξ)=ln⁡(Pr[M(x,u)=r]Pr[M(y,u)=r])=ln⁡(exp⁡(εu(x,r)/Δu)exp⁡(εu(y,r)/Δu)) \\mathcal{L}_{\\mathcal{M}(x)||\\mathcal{M}(y)}^{(\\xi)} = \\ln(\\frac{Pr\\lbrack \\mathcal{M}(x,u) = r \\rbrack}{Pr\\lbrack \\mathcal{M}(y,u) = r \\rbrack}) = \\ln \\Big(\\frac{\\exp(\\varepsilon u(x,r)/\\Delta u)}{\\exp(\\varepsilon u(y,r)/\\Delta u)}\\Big) LM(x)∣∣M(y)(ξ)​=ln(Pr[M(y,u)=r]Pr[M(x,u)=r]​)=ln(exp(εu(y,r)/Δu)exp(εu(x,r)/Δu)​) ) 这种直观的观点忽略了归一化项的某些影响，该归一化项出现的原因是，当有额外的人出现在数据库中，导致某些元素 r∈Rr \\in \\mathcal{R}r∈R 的效用减小而其他元素的效用增大。接下来定义的实际机制将一半的隐私预算用于归一化项的更改。 （个人理解：上述公式仅仅表明，当只有一个的回答 rrr 时，其隐私损失是符合差分隐私定义中的 ε\\varepsilonε。 但当可能有很多个回答时，我们就需要考虑到一个回答占总体回答概率的多少，即上段中提到的 “ 当有额外的人出现在数据库中，导致某些元素 r∈Rr \\in \\mathcal{R}r∈R 的效用减小而其他元素的效用增大 ” 。此处的归一化项（Normalization Term）指的是所有可能出现回答 r′∈Rr' \\in \\mathcal{R}r′∈R 的概率总和，类比离散变量的概率公式，Pr[ME(x,u,R)=r]=exp⁡(εu(x,r)2Δu)∑r′∈Rexp⁡(εu(x,r′)2Δu)Pr[\\mathcal{M}_E(x,u,\\mathcal{R})=r] = \\frac{\\exp(\\frac{\\varepsilon u(x,r)}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})}Pr[ME​(x,u,R)=r]=∑r′∈R​exp(2Δuεu(x,r′)​)exp(2Δuεu(x,r)​)​ 。这也解释了后文指数分布证明中的概率。） 定义3.4（指数机制） 指数机制 ME(x,u,R)\\mathcal{M}_E(x,u,\\mathcal{R})ME​(x,u,R) 选择并输出元素 r∈Rr \\in \\mathcal{R}r∈R 的概率与 exp⁡(εu(x,r)2Δu)\\exp\\big(\\frac{\\varepsilon u(x,r)}{2\\Delta u}\\big)exp(2Δuεu(x,r)​) 成正比。 指数机制可以在较大的任意域上定义复杂的分布，因此当 uuu 的范围在问题的自然参数中超多项式大时，可能无法有效地实现指数机制。 回到南瓜的例子，对数据库 xxx 上的价格 ppp 的效用就是当价格为 ppp 且需求曲线如 xxx 所示时获得的利润。重要的是，潜在价格的范围应与实际出价无关。否则，将存在一个价格，其中一个数据集中的权重为非零，而相邻集合中的权重为零，这违反了差分隐私。 定理 3.10 指数机制满足 (ε,0)(\\varepsilon,0)(ε,0) -差分隐私。 【证明】 为了清楚起见，我们假设指数机制的范围 R\\mathcal{R}R 是有限的，但这是不必要的。在所有的差分隐私证明中，我们考虑指数机制的一个实例,即在两个相邻的数据库 x∈N∣χ∣,y∈N∣χ∣,∣∣x−y∣∣1≤1x \\in \\mathbb{N}^{|\\chi|},y \\in \\mathbb{N}^{|\\chi|},||x-y||_1 \\leq 1x∈N∣χ∣,y∈N∣χ∣,∣∣x−y∣∣1​≤1上输出某个元素 r∈Rr \\in \\mathcal{R}r∈R 的概率之比。 Pr[ME(x,u,R)=r]Pr[ME(y,u,R)=r]=(exp⁡(εu(x,r)2Δu)∑r′∈Rexp⁡(εu(x,r′)2Δu))(exp⁡(εu(y,r)2Δu)∑r′∈Rexp⁡(εu(y,r′)2Δu))=(exp⁡(εu(x,r)2Δu)exp⁡(εu(y,r)2Δu))⋅(∑r′∈Rexp⁡(εu(y,r′)2Δu)∑r′∈Rexp⁡(εu(x,r′)2Δu))=exp⁡(ε(u(x,r′)−u(y,r′))2Δu)⋅(∑r′∈Rexp⁡(εu(y,r′)2Δu)∑r′∈Rexp⁡(εu(x,r′)2Δu))≤exp⁡(ε2)⋅exp⁡(ε2)⋅(∑r′∈Rexp⁡(εu(x,r′)2Δu)∑r′∈Rexp⁡(εu(x,r′)2Δu))=exp⁡(ε) \\begin{aligned} \\frac{Pr[\\mathcal{M}_E(x,u,\\mathcal{R})=r]}{Pr[\\mathcal{M}_E(y,u,\\mathcal{R})=r]} &= \\frac{\\Big(\\frac{\\exp(\\frac{\\varepsilon u(x,r)}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})}\\Big)}{\\Big(\\frac{\\exp(\\frac{\\varepsilon u(y,r)}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(y,r')}{2\\Delta u})}\\Big)}\\\\ &= \\Big(\\frac{\\exp(\\frac{\\varepsilon u(x,r)}{2\\Delta u})}{\\exp(\\frac{\\varepsilon u(y,r)}{2\\Delta u})}\\Big) \\cdot \\Big(\\frac{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(y,r')}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})} \\Big)\\\\ &= \\exp\\Big(\\frac{\\varepsilon(u(x,r')-u(y,r'))}{2\\Delta u} \\Big)\\cdot \\Big(\\frac{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(y,r')}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})}\\Big)\\\\ &\\leq \\exp(\\frac{\\varepsilon}{2})\\cdot\\exp(\\frac{\\varepsilon}{2})\\cdot\\Big(\\frac{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})}\\Big)\\\\ &= \\exp(\\varepsilon) \\end{aligned} Pr[ME​(y,u,R)=r]Pr[ME​(x,u,R)=r]​​=(∑r′∈R​exp(2Δuεu(y,r′)​)exp(2Δuεu(y,r)​)​)(∑r′∈R​exp(2Δuεu(x,r′)​)exp(2Δuεu(x,r)​)​)​=(exp(2Δuεu(y,r)​)exp(2Δuεu(x,r)​)​)⋅(∑r′∈R​exp(2Δuεu(x,r′)​)∑r′∈R​exp(2Δuεu(y,r′)​)​)=exp(2Δuε(u(x,r′)−u(y,r′))​)⋅(∑r′∈R​exp(2Δuεu(x,r′)​)∑r′∈R​exp(2Δuεu(y,r′)​)​)≤exp(2ε​)⋅exp(2ε​)⋅(∑r′∈R​exp(2Δuεu(x,r′)​)∑r′∈R​exp(2Δuεu(x,r′)​)​)=exp(ε)​ 同样，对称情况也成立 Pr[ME(y,u,R)=r]Pr[ME(x,u,R)=r]≥exp⁡(−ε)\\frac{Pr[\\mathcal{M}_E(y,u,\\mathcal{R})=r]}{Pr[\\mathcal{M}_E(x,u,\\mathcal{R})=r]} \\geq \\exp(-\\varepsilon)Pr[ME​(x,u,R)=r]Pr[ME​(y,u,R)=r]​≥exp(−ε) 【补充：原文中，上述公式个人认为有问题，证明的公式中符号有误，下面是个人更正，同时增加证明过程辅助理解。该证明需要用到上文关于指数机制隐私损失部分证明结论，其结论如下： LM(x)∣∣M(y)(ξ)=ln⁡(Pr[ME(x,u,R)=r]Pr[ME(y,u,R)=r])=ln⁡(exp⁡(εu(x,r)/Δ2u)exp⁡(εu(y,r)/Δ2u))=ε[u(x,r)−u(y,r)]/Δ2u≤ε/2⟹exp⁡(εu(x,r)/Δ2u)≤eε/2⋅exp⁡(εu(y,r)/Δ2u)⟹∑r′∈Rexp⁡(εu(x,r′)2Δu)≤eε/2⋅∑r′∈Rexp⁡(εu(y,r′)2Δu) \\begin{aligned} \\mathcal{L}_{\\mathcal{M}(x)||\\mathcal{M}(y)}^{(\\xi)} = \\ln(\\frac{Pr[\\mathcal{M}_E(x,u,\\mathcal{R})=r]}{Pr[\\mathcal{M}_E(y,u,\\mathcal{R})=r]}) &= \\ln \\Big(\\frac{\\exp(\\varepsilon u(x,r)/\\Delta 2u)}{\\exp(\\varepsilon u(y,r)/\\Delta 2u)}\\Big) \\\\ &=\\varepsilon[u(x,r)-u(y,r)]/\\Delta 2u \\leq \\varepsilon/2\\\\ \\implies \\exp(\\varepsilon u(x,r)/\\Delta 2u) &\\leq e^{\\varepsilon/2} \\cdot \\exp(\\varepsilon u(y,r)/\\Delta 2u)\\\\ \\implies \\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u}) &\\leq e^{\\varepsilon/2} \\cdot \\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(y,r')}{2\\Delta u}) \\end{aligned} LM(x)∣∣M(y)(ξ)​=ln(Pr[ME​(y,u,R)=r]Pr[ME​(x,u,R)=r]​)⟹exp(εu(x,r)/Δ2u)⟹r′∈R∑​exp(2Δuεu(x,r′)​)​=ln(exp(εu(y,r)/Δ2u)exp(εu(x,r)/Δ2u)​)=ε[u(x,r)−u(y,r)]/Δ2u≤ε/2≤eε/2⋅exp(εu(y,r)/Δ2u)≤eε/2⋅r′∈R∑​exp(2Δuεu(y,r′)​)​ 很自然的我们由 Δu=max⁡r∈R max⁡x,y:∣∣x−y∣∣1≤1∣u(x,r)−u(y,r)∣\\Delta u = \\max_{r \\in \\mathcal{R}} \\ \\max_{x,y:||x-y||_1 \\leq 1}|u(x,r)-u(y,r)|Δu=maxr∈R​ maxx,y:∣∣x−y∣∣1​≤1​∣u(x,r)−u(y,r)∣ 可以推知 u(x,r)−u(y,r)≤Δuu(x,r)-u(y,r) \\leq \\Delta uu(x,r)−u(y,r)≤Δu ，经过放缩之后得到结论。具体如下： Pr[ME(x,u,R)=r]Pr[ME(y,u,R)=r]=(exp⁡(εu(x,r)2Δu)∑r′∈Rexp⁡(εu(x,r′)2Δu))(exp⁡(εu(y,r)2Δu)∑r′∈Rexp⁡(εu(y,r′)2Δu))=(exp⁡(εu(x,r)2Δu)exp⁡(εu(y,r)2Δu))⋅(∑r′∈Rexp⁡(εu(y,r′)2Δu)∑r′∈Rexp⁡(εu(x,r′)2Δu))=exp⁡(ε(u(x,r)−u(y,r))2Δu)⋅(∑r′∈Rexp⁡(εu(y,r′)2Δu)∑r′∈Rexp⁡(εu(x,r′)2Δu))≤exp⁡(ε2)⋅(exp⁡(ε2)⋅∑r′∈Rexp⁡(εu(x,r′)2Δu)∑r′∈Rexp⁡(εu(x,r′)2Δu))=exp⁡(ε) \\begin{aligned} \\frac{Pr[\\mathcal{M}_E(x,u,\\mathcal{R})=r]}{Pr[\\mathcal{M}_E(y,u,\\mathcal{R})=r]} &= \\frac{\\Big(\\frac{\\exp(\\frac{\\varepsilon u(x,r)}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})}\\Big)}{\\Big(\\frac{\\exp(\\frac{\\varepsilon u(y,r)}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(y,r')}{2\\Delta u})}\\Big)}\\\\ &= \\Big(\\frac{\\exp(\\frac{\\varepsilon u(x,r)}{2\\Delta u})}{\\exp(\\frac{\\varepsilon u(y,r)}{2\\Delta u})}\\Big) \\cdot \\Big(\\frac{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(y,r')}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})} \\Big)\\\\ &= \\exp\\Big(\\frac{\\varepsilon(u(x,r)-u(y,r))}{2\\Delta u} \\Big)\\cdot \\Big(\\frac{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(y,r')}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})}\\Big)\\\\ &\\leq \\exp(\\frac{\\varepsilon}{2})\\cdot\\Big(\\frac{\\exp(\\frac{\\varepsilon}{2}) \\cdot \\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})}{\\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})}\\Big)\\\\ &= \\exp(\\varepsilon) \\end{aligned} Pr[ME​(y,u,R)=r]Pr[ME​(x,u,R)=r]​​=(∑r′∈R​exp(2Δuεu(y,r′)​)exp(2Δuεu(y,r)​)​)(∑r′∈R​exp(2Δuεu(x,r′)​)exp(2Δuεu(x,r)​)​)​=(exp(2Δuεu(y,r)​)exp(2Δuεu(x,r)​)​)⋅(∑r′∈R​exp(2Δuεu(x,r′)​)∑r′∈R​exp(2Δuεu(y,r′)​)​)=exp(2Δuε(u(x,r)−u(y,r))​)⋅(∑r′∈R​exp(2Δuεu(x,r′)​)∑r′∈R​exp(2Δuεu(y,r′)​)​)≤exp(2ε​)⋅(∑r′∈R​exp(2Δuεu(x,r′)​)exp(2ε​)⋅∑r′∈R​exp(2Δuεu(x,r′)​)​)=exp(ε)​ 此处也解释了为什么要用 2Δu2\\Delta u2Δu ，其目的是为了弥补归一化项对机制造成的影响，如若不使用 2Δu2\\Delta u2Δu ，易推知机制的隐私损失为 2ε2\\varepsilon2ε 】 指数机制通常可以提供强大的效用保证，因为随着效用得分的下降，它会指数级折减结果。对于给定的数据库 xxx 和给定的效用函数：u:N∣χ∣×R→Ru:\\mathbb{N}^{|\\chi|} \\times \\mathcal{R} \\to \\mathbb{R}u:N∣χ∣×R→R ，令 OPTu(x)=max⁡r∈Ru(x,r)\\text{OPT}_u(x)=\\max_{r \\in \\mathcal{R}}u(x,r)OPTu​(x)=maxr∈R​u(x,r) 表示任何元素 r∈Rr \\in \\mathcal{R}r∈R 相对于数据库 xxx 的最大效用得分。我们将限制指数机制返回 R\\mathcal{R}R 的“良好”元素的概率，其中“良好”将根据 OPTu(x)\\text{OPT}_u(x)OPTu​(x) 进行度量。这种做法的结果是，返回元素 rrr 的效用得分不太可能低于 OPTu(x)\\text{OPT}_u(x)OPTu​(x) 超过 O(Δu/ε)log⁡∣R∣O(\\Delta u/\\varepsilon)\\log|\\mathcal{R}|O(Δu/ε)log∣R∣ 可加因子。 定理3.11 固定数据库 xxx，令 ROPT=r∈R:u(x,r)=OPTu(x)\\mathcal{R}_{\\text{OPT}}={r \\in \\mathcal{R}:u(x,r)=\\text{OPT}_u(x)}ROPT​=r∈R:u(x,r)=OPTu​(x) 表示 R\\mathcal{R}R 中获得效用分数 OPTu(x)\\text{OPT}_u(x)OPTu​(x) 的元素集合。则： Pr[u(ME(x,u,R))≤OPTu(x)−2Δuε(ln⁡(∣R∣∣ROPT∣)+t)]≤e−t Pr\\Big[u(\\mathcal{M}_E(x,u,\\mathcal{R})) \\leq \\text{OPT}_u(x)-\\frac{2\\Delta u}{\\varepsilon}\\Big(\\ln \\Big(\\frac{|\\mathcal{R}|}{|\\mathcal{R}_{\\text{OPT}}|}\\Big)+t\\Big)\\Big] \\leq e^{-t} Pr[u(ME​(x,u,R))≤OPTu​(x)−ε2Δu​(ln(∣ROPT​∣∣R∣​)+t)]≤e−t 【证明】 Pr[u(ME(x,u,R))≤c]≤∣R∣exp⁡(εc/2Δu)∣ROPT∣exp⁡(εOPTu(x)/2Δu)=∣R∣∣ROPT∣exp⁡(ε(c−OPTu(x))2Δu) \\begin{aligned} Pr\\Big[u(\\mathcal{M}_E(x,u,\\mathcal{R})) \\leq c\\Big] &\\leq \\frac{|\\mathcal{R}|\\exp(\\varepsilon c / 2\\Delta u)}{|\\mathcal{R}_{\\text{OPT}}|\\exp(\\varepsilon \\text{OPT}_u(x)/2\\Delta u)}\\\\ &= \\frac{|\\mathcal{R}|}{|\\mathcal{R}_{\\text{OPT}}|}\\exp\\Big(\\frac{\\varepsilon(c-\\text{OPT}_u(x))}{2\\Delta u} \\Big) \\end{aligned} Pr[u(ME​(x,u,R))≤c]​≤∣ROPT​∣exp(εOPTu​(x)/2Δu)∣R∣exp(εc/2Δu)​=∣ROPT​∣∣R∣​exp(2Δuε(c−OPTu​(x))​)​ 这个不等式是由这样一个观察结果得出的：每一个 r∈R,u(x,r)≤cr\\in \\mathcal{R},u(x,r)\\leq cr∈R,u(x,r)≤c 所具有最大的未归一化概率质量为 exp⁡(εc/2Δu)\\exp(\\varepsilon c/2\\Delta u)exp(εc/2Δu) 1>^{}1>，因此这类“坏”元素 rrr 的整个集合的未归一化概率质量总和最大为 ∣R∣exp⁡(εc/2Δu)|\\mathcal{R}|\\exp(\\varepsilon c/2\\Delta u)∣R∣exp(εc/2Δu) 。与此相反，我们知道至少存在 ∣ROPT∣≥1|\\mathcal{R}_{\\text{OPT}}|\\geq 1∣ROPT​∣≥1 个元素具有 u(x,r)=OPTu(x)u(x,r)=\\text{OPT}_u(x)u(x,r)=OPTu​(x) ，并且因此未归一化概率质量为 exp⁡(εOPTu(x)/2Δu)\\exp(\\varepsilon \\text{OPT}_u(x)/2\\Delta u)exp(εOPTu​(x)/2Δu) ，因此这是正规化项的下界。 这个定理是通过插入c的适当值得出的。 （注：概率质量（probability mass）：离散随机变量在各特定取值上的概率，概率质量函数是对离散随机变量定义的，本身代表该值的概率；概率密度函数是对连续随机变量定义的，本身不是概率，只有对连续随机变量的概率密度函数在某区间内进行积分后才是概率。其定义为：假设 XXX 是一个定义在可数样本空间 SSS 上的离散随机变量 S⊆RS \\subseteq \\mathbb{R}S⊆R，则其概率质量函数 fX(x)f_{X}(x)fX​(x) 为: fX(x)={Pr⁡(X=x),x∈S,0,x∈R\\S. f_{X}(x)={\\begin{cases}\\Pr(X=x),&x\\in S,\\\\0,&x\\in {\\mathbb {R}}\\backslash S.\\end{cases}} fX​(x)={Pr(X=x),0,​x∈S,x∈R\\S.​ ） 【补充 根据定义，每一个 r∈Rr\\in \\mathcal{R}r∈R，且其效用得分是 u(x,r)≤cu(x,r)\\leq cu(x,r)≤c ，所有这些 rrr 的未归一化概率质量最大不超过 exp⁡(εc/2Δu)\\exp(\\varepsilon c/2\\Delta u)exp(εc/2Δu)。那么这些 rrr 的概率总和为：∣R∣exp⁡(εc/2Δu)|\\mathcal{R}|\\exp(\\varepsilon c/2\\Delta u)∣R∣exp(εc/2Δu)。我们又知道，ROPT⊆R\\mathcal{R}_{\\text{OPT}} \\subseteq \\mathcal{R}ROPT​⊆R，所以 ∣ROPT∣exp⁡(εOPTu(x)/2Δu)≤∑r′∈Rexp⁡(εu(x,r′)2Δu)|\\mathcal{R}_{\\text{OPT}}|\\exp(\\varepsilon \\text{OPT}_u(x)/2\\Delta u) \\leq \\sum_{r'\\in \\mathcal{R}}\\exp(\\frac{\\varepsilon u(x,r')}{2\\Delta u})∣ROPT​∣exp(εOPTu​(x)/2Δu)≤∑r′∈R​exp(2Δuεu(x,r′)​)。分子增大，分母减少，故下面不等式成立： Pr[u(ME(x,u,R))≤c]≤∣R∣exp⁡(εc/2Δu)∣ROPT∣exp⁡(εOPTu(x)/2Δu) Pr\\Big[u(\\mathcal{M}_E(x,u,\\mathcal{R})) \\leq c\\Big] \\leq \\frac{|\\mathcal{R}|\\exp(\\varepsilon c / 2\\Delta u)}{|\\mathcal{R}_{\\text{OPT}}|\\exp(\\varepsilon \\text{OPT}_u(x)/2\\Delta u)} Pr[u(ME​(x,u,R))≤c]≤∣ROPT​∣exp(εOPTu​(x)/2Δu)∣R∣exp(εc/2Δu)​ 我们将不等式右边变形推导得到： Pr[u(ME(x,u,R))≤c]≤∣R∣exp⁡(εc/2Δu)∣ROPT∣exp⁡(εOPTu(x)/2Δu)=exp⁡(ln⁡(∣R∣∣ROPT∣)+ε(c−OPTu(x))2Δu) \\begin{aligned} Pr\\Big[u(\\mathcal{M}_E(x,u,\\mathcal{R})) \\leq c\\Big] &\\leq \\frac{|\\mathcal{R}|\\exp(\\varepsilon c / 2\\Delta u)}{|\\mathcal{R}_{\\text{OPT}}|\\exp(\\varepsilon \\text{OPT}_u(x)/2\\Delta u)}\\\\ &= \\exp\\Big(\\ln\\big(\\frac{|\\mathcal{R}|}{|\\mathcal{R}_{\\text{OPT}}|}\\big) + \\frac{\\varepsilon(c-\\text{OPT}_u(x))}{2\\Delta u} \\Big)\\\\ \\end{aligned} Pr[u(ME​(x,u,R))≤c]​≤∣ROPT​∣exp(εOPTu​(x)/2Δu)∣R∣exp(εc/2Δu)​=exp(ln(∣ROPT​∣∣R∣​)+2Δuε(c−OPTu​(x))​)​ 令 −t=ln⁡(∣R∣∣ROPT∣)+ε(c−OPTu(x))2Δu-t = \\ln\\big(\\frac{|\\mathcal{R}|}{|\\mathcal{R}_{\\text{OPT}}|}\\big) + \\frac{\\varepsilon(c-\\text{OPT}_u(x))}{2\\Delta u}−t=ln(∣ROPT​∣∣R∣​)+2Δuε(c−OPTu​(x))​ 求得 c=OPTu(x)−2Δuε(ln⁡(∣R∣∣ROPT∣)+t)c=\\text{OPT}_u(x)-\\frac{2\\Delta u}{\\varepsilon}\\Big(\\ln \\Big(\\frac{|\\mathcal{R}|}{|\\mathcal{R}_{\\text{OPT}}|}\\Big)+t\\Big)c=OPTu​(x)−ε2Δu​(ln(∣ROPT​∣∣R∣​)+t) 将 ccc 带入不等式即为 定理3.11 所示。 】 由于我们总是有 ∣ROPT∣≥1|\\mathcal{R}_{\\text{OPT}}|\\geq 1∣ROPT​∣≥1，我们可以更普遍地使用以下简单的推论： 推论 3.12 定义一个数据库 xxx，我们有： Pr[u(ME(x,u,R))≤OPTu(x)−2Δuε(ln⁡(∣R∣)+t)]≤e−t Pr\\Big[u(\\mathcal{M}_E(x,u,\\mathcal{R})) \\leq \\text{OPT}_u(x)-\\frac{2\\Delta u}{\\varepsilon}(\\ln (|\\mathcal{R}|)+t)\\Big] \\leq e^{-t} Pr[u(ME​(x,u,R))≤OPTu​(x)−ε2Δu​(ln(∣R∣)+t)]≤e−t 从定理3.11和推论3.12的证明中可以看出，指数机制特别容易分析。 例3.6（二选一） 考虑一个简单的问题，即确定 A 和 B 两种疾病中哪一种更常见。假设疾病A的真实计数为 0，疾病B的真实计数为 c>0c>0c>0。我们的效用概念将与实际计数联系起来，这样计数越大的疾病种类将具有更高的效用，且Δu=1\\Delta u=1Δu=1。因此，A 的效用为 0，B 的效用为 c。使用指数机制，我们可以立即应用推论3.12，输出错误结果 A 概率至多为 2e−c(ε/(2Δu))=2e−cε/22e^{-c(\\varepsilon / (2\\Delta u))}=2e^{-c\\varepsilon/2}2e−c(ε/(2Δu))=2e−cε/2 。 【补充：此处 A 的效用为 0 ，则 Pr[u(ME(x,u,R))≤0]Pr\\Big[u(\\mathcal{M}_E(x,u,\\mathcal{R}))\\leq 0\\Big]Pr[u(ME​(x,u,R))≤0] 由 推论3.12，令 OPTu(x)−2Δuε(ln⁡(∣R∣)+t)=0\\text{OPT}_u(x)-\\frac{2\\Delta u}{\\varepsilon}(\\ln (|\\mathcal{R}|)+t) = 0OPTu​(x)−ε2Δu​(ln(∣R∣)+t)=0，由于 ∣R∣=2,Δu=1,OPTu(x)=c|\\mathcal{R}|=2,\\Delta u=1,\\text{OPT}_u(x)=c∣R∣=2,Δu=1,OPTu​(x)=c 可以推得 t=cε/2−ln⁡2t = c\\varepsilon/2-\\ln2t=cε/2−ln2，即： Pr[u(ME(x,u,R))≤OPTu(x)−2ε(ln⁡2+t)]≤e−tPr[u(ME(x,u,R))≤0]≤e−(cε/2−ln⁡2)Pr[u(ME(x,u,R))≤0]≤2e−cε/2 \\begin{aligned} Pr\\Big[u(\\mathcal{M}_E(x,u,\\mathcal{R})) \\leq \\text{OPT}_u(x)-\\frac{2}{\\varepsilon}(\\ln2+t)\\Big] &\\leq e^{-t}\\\\ Pr\\Big[u(\\mathcal{M}_E(x,u,\\mathcal{R})) \\leq 0\\Big] &\\leq e^{-(c\\varepsilon/2-\\ln2)}\\\\ Pr\\Big[u(\\mathcal{M}_E(x,u,\\mathcal{R})) \\leq 0\\Big] &\\leq 2e^{-c\\varepsilon/2}\\\\ \\end{aligned} Pr[u(ME​(x,u,R))≤OPTu​(x)−ε2​(ln2+t)]Pr[u(ME​(x,u,R))≤0]Pr[u(ME​(x,u,R))≤0]​≤e−t≤e−(cε/2−ln2)≤2e−cε/2​ 】 分析 Report Noisy Max 似乎更为复杂，因为它需要了解当添加到 A 的计数中的噪声为正而添加到 B 的计数中的噪声为负时（概率为1/4）情况下会发生什么。 如果向数据集中添加元素不能导致函数值减小，则函数在数据集中是单调的。计数查询是单调的；通过向买家集合提供固定价格而获得的收入也是单调的。 考虑 Report One-Sided Noisy Arg-Max 机制，在单调效用的情况下，该机制将噪声（从参数为 ε/Δu\\varepsilon/\\Delta uε/Δu 的单侧指数分布中提取）添加到每个潜在输出的效用函数中；或在非单调效用的情况下，添加的噪声从参数为 ε/2Δu\\varepsilon/2\\Delta uε/2Δu 的单侧指数分布中提取，并报告最大结果。 使用该算法，其隐私证明几乎与 Report Noisy Max 相同（但当效用函数是非单调时造成了两倍损失），我们立即在上面的示例3.6中推得，选中输出疾病 A 的概率比结果 B 小，输出疾病 A 的概率等于参数为 c(ε/Δu)=cεc(\\varepsilon/\\Delta u)=c\\varepsilonc(ε/Δu)=cε 的指数分布。 定理3.13 当 Report One-Sided Noisy Arg-Max 机制使用参数 ε/2Δu\\varepsilon/2\\Delta uε/2Δu 运行时，在输出上会产生与指数机制相同的分布。 Copyright © GuoJohnny 2019 all right reserved，powered by Gitbook修订时间： 2019-11-22 08:53:45 "}}