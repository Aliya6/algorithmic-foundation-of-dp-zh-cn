# 2.3 形式化差分隐私（1）

我们将从差分隐私的技术定义开始，然后继续解释它。差分隐私将通过过程提供隐私；特别是它将引入随机性。最早的隐私保护做法是使用随机响应技术，这是一种在社会科学中发展起来的技术，用于收集有关禁运或非法行为的统计信息（通过是否拥有财产 $P$ 判断）。研究参与者通过下列做法报告他们是否有财产 $P$：

* 1.掷硬币。

* 2.如果是反面，那就如实回答。

* 3.如果是正面，则掷第二枚硬币，正面回答“是”，反面回答“否”。

“隐私”来源于对任何输出的合理否认；特别是，如果拥有财产 $P$ 相当于从事非法行为，即使是“是”答案也不构成犯罪，因为无论被告是否实际拥有财产 $P$ ，这个答案出现的概率至少为 $1/4$。准确度来自于对噪声产生过程的理解（随机分组中引入虚假的“是”和“否”答案）：预期的“是”答案的概率是：没有属性 $P$ 的参与者概率的 $1/4$ 加上有属性 $P$ 的概率的 $3/4$ 。因此，如果 $p$ 是具有 $p$ 属性的参与者的真实概率，则“是”答案的预期概率为 $(1/4)(1-p)+(3/4)p=(1/4)+p/2$。因此，我们可以将 $p$ 估计为回答“是”的概率的两倍减去 $1/2$ ，即 $2((1/4)+p/2)-1/2$ (*此处个人感觉有误*) 。


*注：此处令 $P_A$ 为真实的概率，$P_B$ 为经过机制变换后得到的概率，
这样，可以由变换之后的概率$P_B$得到真实概率$P_A$:*

$$
\begin{aligned}
P_B &=  1/4 (1 - P_A) + 3/4 P_A \\
&= 1/4 + 1/2 P_A \\
P_A &= 2 * P_B - 1/2
\end{aligned}
$$

（*上述的例子可以得出，经过随机化之后，对个人数据是会有不确定性，无法得知个人是什么样的属性，但最后经过“抛硬币机制”处理后得到的总体概率却能还原出数据集原有总体概率。可以尝试，将原有的 $P_A$ 取任何值，都能从最后的 $P_B$ 还原出来，但此时单个个体的属性是随机化的。*）

随机化是必不可少的；更确切地说，任何非平凡的隐私都要对所有现有的或未来的辅助信息来源随机化处理（包括其他数据库、研究、网站、在线社区、闲话、报纸、政府统计等等）。下面我们来说明一个简单的混合参数。出于矛盾的原因，我们假设有一个非平凡的确定性算法。存在一个查询，并且有两个数据库在此查询下产生不同的输出。一次更改一行，我们看到存在一对仅在单行值上有所不同的数据库，在同一数据库上同一查询产生不同的输出。 知道该数据库是这两个几乎完全相同的数据库之一的对手将了解未知行中数据的值。

（*注1：“**非平凡的**” 具有一定复杂度，需要一定脑力活动、加工过程才能得到的结果或结论。The antonym nontrivial is commonly used by engineers and mathematicians to indicate a statement or theorem that is not obvious or easy to prove. 摘自wikipedia*） 

（*注2:为引入随机化和相邻数据集做铺垫。*）

因此，我们将需要讨论随机算法的输入和输出空间。 在本专论中，我们使用离散的概率空间。 有时我们会将算法描述为从连续分布中采样，但是应始终以适当的方式将其离散化为有限精度（请参见后文的备注2.1）。 通常，具有域 $A$ 和（离散）范围 $B$ 的随机算法将与从$A$到$B$上的概率单纯形的映射相关联，表示为$\Delta(B)$：

**定义2.1（概率单纯形）**  给定一个离散集 $B$，将 $B$ 上的概率单纯形，表示为 $\Delta(B)$ ，其定义为：  

$$
\Delta(B) = \{ x \in \mathbb{R}^{|B|} : x_i \geqslant 0\    for\ all\ i\ and\ \sum_{i=1}^{|B|}x_i = 1 \}
$$
  
（*个人理解：此处的 $\mathbb{R}$ 可以与数据库中的数据集合类比，$x_i$ 即映射后得到数据的类概率，将数据集映射到各个离散状态集合 $B$ 的元素中，且这些映射产生离散点 $x_i$ 的概率之和为 $1$*）

（*个人理解2:对概率单纯形定义进行拓展，即有一个包含$\mathbb{R}^{|B|}$个分量的向量$\overrightarrow{x}$,其分量之和为$1$,如下：*
$$
\begin{aligned}
\overrightarrow{x} \in \mathbb{R}^{|B|},\overrightarrow{x} = (x_1,x_2...x_{|B|})  \\ 
x_i \in \overrightarrow{x},\sum_{i=1}^{|B|}x_i = 1,and \ x_i \geqslant 0 \\
\end{aligned}
$$
$\ \ \ \ \ \ e.g. \  as \ the \ coin \ flip:$
$$
\begin{aligned}

if \  \overrightarrow{B} = \{ 0,1 \},then \ \mathbb{R}^{|B|} = R \times R  \\
\overrightarrow{x} \in R \times R \ (i.e:(x_1,x_2) \in \overrightarrow{x})  \\
\sum_{i=1}^{|B|}x_i = \sum_{i=1}^{2}x_i = x_1 + x_2 = 1
\end{aligned}
$$

）

**定义2.2（随机化算法）** 具有域$A$和离散范围$B$的随机算法$\mathcal{M}$ 与 映射 $M:A \to \Delta(B)$相关联。 在输入$a∈A$时，算法$\mathcal{M}$以概率$M(a)_b$输出$\mathcal{M}(a)=b$（$b∈B$）。概率空间包括了硬币翻转算法$\mathcal{M}$的概率空间。

（*个人理解：$\mathcal{M}$ 是种映射算法（机制），将原始域数据成为其他离散形式（比如直方图）。上文的翻转硬币机制就是该定义中的 $\mathcal{M}$  。此处的$\mathcal{M}$与映射 $M:A \to \Delta(B)$有联系但不相同，$\mathcal{M}$指将原始数据变成其他数据的方法，$M:A \to \Delta(B)$是指从$A \to B$的各个映射的概率。）*）

我们将数据库 $x$ 视为来自全集 $\mathcal{X}$ 的记录的集合。用它们的直方图表示数据库通常会很方便：$x \in \mathbb{N}^{|\mathcal{X}|}$ ，其中每个项  $x_i$ 表示数据库 $x$ 中类型 $i\in\mathcal{X}$ 元素的数量。（我们略微滥用了符号，让符号 $\mathbb{N}$ 表示所有非负整数的集合，包括零）。 在这个表示中，两个数据库 $x$ 和 $y$ 之间距离的自然度量将是它们的     $\ell_1$ 距离：

**定义 2.3 (数据库之间距离)** 将数据库的$\ell_1$ 范数距离表示为 $||x||_1$ 其定义为:

$$
||x||_1 = \sum_{i=1}^{|\mathcal{X}|}|x_i|
$$

数据库 $x$ 和 $y$ 之间的 $\ell_1$ 距离为 $||x-y||_1$

注意到 $||x||_1$ 是衡量数据库 $x$ 的大小（也就是说，数据库 $x$ 包含的记录数），而 $||x-y||_1$ 表示数据库 $x$ 和 $y$ 之间相差多少条记录。我们称这种记录相差为1的数据库为相邻数据集。

数据库也可以由行的多集（ $\mathcal{X}$ 的元素）甚至行的有序列表来表示(这是一组的特例,其中行号成为元素名称的一部分)。 在这种情况下，数据库之间的距离通常由汉明距离（即汉明距离不同）来衡量。  

但是，除非另有说明，否则我们将使用上述直方图表示形式。 （但是请注意，即使直方图表示法在数学上更方便，在实际的实现中，多集表示通常也会更加简洁）。  

现在，我们可以正式定义差分隐私了，这将直观地保证随机算法在相似输入数据库上的行为类似。 

**定义2.4 （差分隐私）** 对于所有的$\mathcal{S} \subseteq Range(\mathcal{M})$ 且所有的 $x,y\in \mathbb{N}^{|\mathcal{X}|}$ 有 $||x-y||_1 \leq 1$，如果满足下列关系：

$$
\text{Pr}[\mathcal{M}(x) \in \mathcal{S}] \leq exp(\varepsilon)\text{Pr}[\mathcal{M}(y) \in \mathcal{S}] + \delta
$$

则将这个域在 $\mathbb{N}^{|\mathcal{X}|}$ 的随机算法 $\mathcal{M}$ 称为 $(\varepsilon,\delta)$ 差分隐私(即 $(\varepsilon,\delta) \text{--} Differentially \ private$)。  

特别的，如果 $\delta=0$ ，则将 $\mathcal{M}$ 称为 $\varepsilon$ 差分隐私(即 $\varepsilon \text{--} Differentially \ private$)。

通常，我们对 $\delta$ 的值感兴趣，该值小于多项式数据库大小的倒数。 特别是，$\delta$  值接近 $1/||x||_1$ 是非常危险（因为在第1节中讨论“少数人”原则）：这种做法通过发布少量数据库参与者的完整记录来“保护隐私”（以获得可用性）。 

但是，即使 $\delta$ 可以忽略不计，$\varepsilon$ 和 $(\varepsilon,\delta)$-  差分隐私之间也存在理论上的区别。 其中最主要的是量化顺序的转换。 $\varepsilon$- 差分隐私可确保对于机制 $\mathcal{M}(x)$ 的每次运行，在每个相邻数据库上同时观察到的输出的可能性几乎相同。相反，从事后观察值得出结论， $(\varepsilon,\delta)$-  差分隐私对于每对相邻数据库$x, \ y$，当数据库是$x$，而不是$y$时，机制  $\mathcal{M}$ 或更大概率生成或小概率生成值 $\mathcal{M}(x)$ 。 但是，给定输出$\xi \backsim \mathcal{M}(x)$，可能会找到一个数据库$y$，使得 $\xi$ 在 $y$ 上产生的可能性比数据库为 $x$ 时的可能性大得多。 即，分布 $\mathcal{M}(y)$ 中的 $\xi$ 的质量可以实质上大于分布 $\mathcal{M}(x)$ 中的 $\xi$ 的质量。

所以，机制质量：

$$
\mathcal{L}_{\mathcal{M}(x)||\mathcal{M}(y)}^{(\xi)} = \ln(\frac{\text{Pr}\lbrack \mathcal{M}(x) = \xi \rbrack}{\text{Pr}\lbrack \mathcal{M}(y) = \xi \rbrack})
$$
对我们至关重要。我们将其称为观察 $\xi$ 导致的**隐私损失**。 这种损失可能是正的（当事件在$x$之下比在$y$之下更有可能发生），也可能是负的（当事件在$y$之下比$x$之下更有可能）。正如我们将在**引理3.17**看到，$(\varepsilon,\delta)$-  差分隐私确保对于所有相邻的$x$、$y$，隐私损失的绝对值被$\varepsilon$界定的概率至少为$1-\delta$。 与往常一样，概率空间位于机制$\mathcal{M}$的硬币上。（*over the coins of machanism $\mathcal{M}$?这句话原文无法理解。*）

差分隐私不受后处理的影响：在没有其他有关私有数据库的知识的情况下，数据分析人员无法计算私有算法$\mathcal{M}$的输出函数，也无法使其差分隐私程度降低。 就是说，如果算法保护了个人的隐私，那么无论是在正式定义下，还是在任何直观的意义上，数据分析师都无法仅仅通过坐在角落里思考算法的输出来增加隐私损失。 形式上，具有（$(\varepsilon,\delta)$-  差分隐私算法$\mathcal{M}$的数据独立映射 $f$ 的合成也具有（$(\varepsilon,\delta)$-  差分隐私：

**命题2.1（后处理）** 令 $\mathcal{M}: \mathbb{N}^{|\mathcal{X}|} \to R$ 是 $(\varepsilon,\delta)$-  差分隐私随机算法。 令 $f:R \to R'$为任意随机映射。 则 $f \circ \mathcal{M}: \mathbb{N}^{|\mathcal{X}|} \to R'$ 是 $(\varepsilon,\delta)$- 差分隐私。

【证明】我们证明了一个确定性函数$f:R \to R'$的命题。结果如下，因为任何随机映射都可以分解为确定性函数的凸组合，而差分隐私机制的凸组合是差分隐私的。

设任意一对相邻数据库 $x,y$ 的 $||x-y||_1 \leq 1$，且任意事件 $S\subseteq R'$，设 $T = \{ r \in R: f(r) \in S \}$ ，则：

$$
\begin{aligned}
   \text{Pr}\lbrack f(\mathcal{M}(x) \in S) \rbrack &= \text{Pr}[\mathcal{M}(x) \in T]\\
   & \leq exp(\varepsilon)\text{Pr}[\mathcal{M}(y) \in T] + \delta\\
   &= exp(\varepsilon)\text{Pr}[f(\mathcal{M}(y)) \in S] + \delta
\end{aligned}
$$
即证。

